{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **Action:** Read Excel Sheet to Dataframe\n",
    "*   **Source:** `G:\\My Drive\\stocks\\finviz_scrape.xlsm, Sheet:yyyy-mm-dd`\n",
    "*   **Destination:** `c:\\Users\\ping\\Files_win10\\python\\py310\\stocks\\temp\\df_finviz.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel file path and sheet name\n",
    "file_path = r\"G:\\My Drive\\stocks\\finviz_scrape.xlsm\"  # r for raw string\n",
    "stocks = \"S20250306\"\n",
    "etfs = \"E20250306\"\n",
    "sheets = [stocks, etfs]\n",
    "\n",
    "\n",
    "# File name to be saved pickle df\n",
    "pickle_stocks_file_name = \"df_finviz_stocks.pkl\"\n",
    "pickle_etfs_file_name = \"df_finviz_ETFs.pkl\"\n",
    "\n",
    "print(f'file_path: \"{file_path}\"')\n",
    "print(f'stocks: {stocks}')\n",
    "print(f'etfs: {etfs}')\n",
    "print(f'sheets: {sheets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for sheet in sheets:\n",
    "  df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "  # Set the 'Ticker' column as the index\n",
    "  if 'Ticker' in df.columns:  # Check if 'Ticker' column exists\n",
    "      df = df.set_index('Ticker')\n",
    "  else:\n",
    "      print(f\"Warning: 'Ticker' column not found in sheet '{sheet_name}'.\")\n",
    "\n",
    "  dfs[sheet_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[stocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet_name, df in dfs.items():  # Iterate over the dictionary of DataFrames.items():\n",
    "    print(f\"\\nDataFrame for sheet: {sheet_name}\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Remove \"B\" and convert to numeric\n",
    "df['AUM'] = (\n",
    "    df['AUM']\n",
    "    .astype(str)  # Ensure we're working with strings\n",
    "    .str.replace('B', '', regex=False)  # Remove \"B\" explicitly\n",
    "    .str.replace(',', '', regex=False)  # Optional: Remove commas if present\n",
    "    .apply(pd.to_numeric, errors='coerce')  # Convert to float, invalid → NaN\n",
    ")\n",
    "\n",
    "# Columns to process (all except 'Tags')\n",
    "cols_to_process = df.columns.difference(['Tags'])\n",
    "\n",
    "# Step 1: Create a mask for cells that are exactly \"-\" (standalone hyphen)\n",
    "mask = df[cols_to_process].apply(lambda x: x.astype(str) == '-')\n",
    "\n",
    "# Step 2: Replace standalone hyphens with NaN\n",
    "df[cols_to_process] = df[cols_to_process].mask(mask, np.nan)\n",
    "\n",
    "# Step 3: Convert to float (coerce invalid values like \"150-200\" to NaN)\n",
    "df[cols_to_process] = df[cols_to_process].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# # Convert Tags column from object to string\n",
    "df['Tags'] = df['Tags'].convert_dtypes()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Remove \"B\" and convert to numeric\n",
    "df['Market Cap'] = (\n",
    "    df['Market Cap']\n",
    "    .astype(str)  # Ensure we're working with strings\n",
    "    .str.replace('B', '', regex=False)  # Remove \"B\" explicitly\n",
    "    .str.replace(',', '', regex=False)  # Optional: Remove commas if present\n",
    "    .apply(pd.to_numeric, errors='coerce')  # Convert to float, invalid → NaN\n",
    ")\n",
    "\n",
    "# Columns to process (all except 'Industry')\n",
    "cols_to_process = df.columns.difference(['Industry'])\n",
    "\n",
    "# Step 1: Create a mask for cells that are exactly \"-\" (standalone hyphen)\n",
    "mask = df[cols_to_process].apply(lambda x: x.astype(str) == '-')\n",
    "\n",
    "# Step 2: Replace standalone hyphens with NaN\n",
    "df[cols_to_process] = df[cols_to_process].mask(mask, np.nan)\n",
    "\n",
    "# Step 3: Convert to float (coerce invalid values like \"150-200\" to NaN)\n",
    "df[cols_to_process] = df[cols_to_process].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# # Convert Industry column from object to string\n",
    "df['Industry'] = df['Industry'].convert_dtypes()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Create temp directory if it doesn't exist\n",
    "temp_dir_path = os.path.join(current_path, 'temp')\n",
    "if not os.path.exists(temp_dir_path):\n",
    "  os.makedirs(temp_dir_path)\n",
    "  print(f\"Created temp directory at: {temp_dir_path}\")\n",
    "else:\n",
    "  print(f\"Temp directory already exists at: {temp_dir_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Create the full path for the pickle file\n",
    "pickle_path = os.path.join(temp_dir_path, pickle_file_name)\n",
    "\n",
    "# Save the DataFrame to pickle file\n",
    "with open(pickle_path, 'wb') as f:\n",
    "  pickle.dump(df, f)\n",
    "\n",
    "print(f\"DataFrame saved to: {pickle_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
