{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Most Recent Files in Downloads:\n",
      "  - Name: CursorUserSetup-x64-0.46.8.exe\n",
      "    Size: 106.36 MB\n",
      "    Last Modified: 2025-03-02 08:23:57\n",
      "  - Name: _df.pkl\n",
      "    Size: 34.09 MB\n",
      "    Last Modified: 2025-02-28 16:58:12\n",
      "  - Name: OHLCV.pkl\n",
      "    Size: 46.35 MB\n",
      "    Last Modified: 2025-02-28 16:48:26\n",
      "  - Name: download_stocks_ETFs_OHLCV_v3.ipynb\n",
      "    Size: 361.86 KB\n",
      "    Last Modified: 2025-02-28 16:45:16\n",
      "  - Name: adj_close_prices_data.csv\n",
      "    Size: 4.59 KB\n",
      "    Last Modified: 2025-02-28 11:54:22\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def get_latest_downloaded_files(directory, num_files=10):\n",
    "    \"\"\"\n",
    "    Lists the N most recent files in a directory, sorted by modification time.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the directory to search.\n",
    "        num_files (int): The number of files to list (default: 10).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "              (filename, file_size_bytes, last_modified_time)\n",
    "              Returns an empty list if the directory doesn't exist or is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"Error: Directory '{directory}' not found.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        files = [(f, os.path.getsize(os.path.join(directory, f)), os.path.getmtime(os.path.join(directory, f)))\n",
    "                 for f in os.listdir(directory)\n",
    "                 if os.path.isfile(os.path.join(directory, f))]  # Check if it's a file\n",
    "\n",
    "        # Sort files by modification time (most recent first)\n",
    "        files.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "        return files[:num_files]  # Return the top N files\n",
    "    except OSError as e:\n",
    "        print(f\"Error accessing directory: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Number of files to retrieve\n",
    "    num_files = 5\n",
    "    \n",
    "    # Get the user's Downloads directory\n",
    "    downloads_dir = os.path.expanduser(\"~\\\\Downloads\")  # Windows-specific\n",
    "\n",
    "    recent_files = get_latest_downloaded_files(downloads_dir, num_files=num_files)\n",
    "\n",
    "    if recent_files:\n",
    "        print(f\"{num_files} Most Recent Files in Downloads:\")\n",
    "        for filename, size, last_modified_time in recent_files:\n",
    "            # Format file size for readability\n",
    "            size_kb = size / 1024\n",
    "            size_mb = size_kb / 1024\n",
    "            if size_mb > 1:\n",
    "                file_size = f\"{size_mb:.2f} MB\"\n",
    "            elif size_kb > 1:\n",
    "                file_size = f\"{size_kb:.2f} KB\"\n",
    "            else:\n",
    "                file_size = f\"{size} bytes\"\n",
    "            \n",
    "            # Format last modified time\n",
    "            formatted_time = datetime.datetime.fromtimestamp(last_modified_time).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            print(f\"  - Name: {filename}\")\n",
    "            print(f\"    Size: {file_size}\")\n",
    "            print(f\"    Last Modified: {formatted_time}\")\n",
    "    else:\n",
    "        print(\"No files found in the Downloads directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve pickled dataframe with symbols' OHLCV\n",
    "filename = \"OHLCV.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_download_path(filename):\n",
    "  \"\"\"\n",
    "  Constructs the full path to a file in the Windows Downloads directory.\n",
    "\n",
    "  Args:\n",
    "    filename: The name of the file.\n",
    "\n",
    "  Returns:\n",
    "    A string representing the absolute path to the file, or None if the\n",
    "    Downloads directory cannot be found.\n",
    "  \"\"\"\n",
    "  if os.name == 'nt':  # Check if running on Windows\n",
    "    try:\n",
    "      # Method 1: Using the 'USERPROFILE' environment variable\n",
    "      downloads_path = os.path.join(os.environ['USERPROFILE'], 'Downloads')\n",
    "      full_path = os.path.join(downloads_path, filename)\n",
    "      return full_path\n",
    "    except KeyError:\n",
    "      # Method 2: If 'USERPROFILE' isn't set, try 'HOMEPATH'\n",
    "      try:\n",
    "          downloads_path = os.path.join(os.environ['HOMEDRIVE'], os.environ['HOMEPATH'], 'Downloads')\n",
    "          full_path = os.path.join(downloads_path, filename)\n",
    "          return full_path\n",
    "      except KeyError:\n",
    "        print(\"Error: Unable to find the Downloads directory using environment variables.\")\n",
    "        return None\n",
    "  else:\n",
    "    print(\"This function is designed for Windows systems.\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full path to 'OHLCV.pkl' is: C:\\Users\\ping\\Downloads\\OHLCV.pkl\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "full_path = get_download_path(filename)\n",
    "\n",
    "if full_path:\n",
    "  print(f\"The full path to '{filename}' is: {full_path}\")\n",
    "else:\n",
    "  print(f\"Could not determine the full path to '{filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 630966 entries, ('AAPL', Timestamp('2025-02-28 00:00:00')) to ('IBTE', Timestamp('2024-03-01 00:00:00'))\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Open       630966 non-null  float64\n",
      " 1   High       630966 non-null  float64\n",
      " 2   Low        630966 non-null  float64\n",
      " 3   Close      630966 non-null  float64\n",
      " 4   Adj Close  630966 non-null  float64\n",
      " 5   Volume     630764 non-null  Int64  \n",
      " 6   Adj Open   630966 non-null  float64\n",
      " 7   Adj High   630966 non-null  float64\n",
      " 8   Adj Low    630966 non-null  float64\n",
      "dtypes: Int64(1), float64(8)\n",
      "memory usage: 46.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from the pickle file\n",
    "df = pd.read_pickle(full_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pyfolio as pf\n",
    "import empyrical  # Import the empyrical package\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Module \\\"zipline.assets\\\" not found.*\")\n",
    "\n",
    "def calculate_performance_metrics(returns, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Calculates Sortino Ratio, Sharpe Ratio, and Omega Ratio using PyFolio/Empyrical.\n",
    "\n",
    "    Args:\n",
    "        returns (pd.Series or np.array):  Daily returns of the investment.\n",
    "                                         Must be a Pandas Series with a DatetimeIndex.\n",
    "        risk_free_rate (float):  The risk-free rate (annualized). Default is 0.0.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated ratios.\n",
    "              Returns None if there is an error or the input is invalid.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Ensure returns is a pandas Series with a DatetimeIndex.  Crucial for pyfolio.\n",
    "        if not isinstance(returns, pd.Series):\n",
    "            returns = pd.Series(returns)  # Convert to Series if needed\n",
    "        if not isinstance(returns.index, pd.DatetimeIndex):\n",
    "            raise ValueError(\"Returns must be a Pandas Series with a DatetimeIndex.\")\n",
    "\n",
    "        # Convert annualized risk-free rate to daily rate\n",
    "        days_per_year = 252  # Standard for financial calculations\n",
    "        daily_risk_free_rate = risk_free_rate / days_per_year\n",
    "\n",
    "        # Calculate the Sharpe Ratio using empyrical (as pyfolio's is deprecated)\n",
    "        sharpe_ratio = empyrical.sharpe_ratio(returns, risk_free=daily_risk_free_rate, annualization=days_per_year)\n",
    "\n",
    "        # Calculate the Sortino Ratio using empyrical\n",
    "        sortino_ratio = empyrical.sortino_ratio(returns, required_return=daily_risk_free_rate, annualization=days_per_year)\n",
    "\n",
    "        # Calculate the Omega Ratio using empyrical\n",
    "        omega_ratio = empyrical.omega_ratio(returns, risk_free=daily_risk_free_rate, annualization=days_per_year)\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"Sharpe Ratio\": sharpe_ratio,\n",
    "            \"Sortino Ratio\": sortino_ratio,\n",
    "            \"Omega Ratio\": omega_ratio\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_returns(adj_close_prices):\n",
    "    \"\"\"\n",
    "    Calculates daily returns from adjusted close prices.\n",
    "\n",
    "    Args:\n",
    "        adj_close_prices (pd.Series): Pandas Series of adjusted close prices with DatetimeIndex.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Pandas Series of daily returns with DatetimeIndex, sorted by date (oldest to newest).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(adj_close_prices, pd.Series):\n",
    "            raise TypeError(\"Input must be a Pandas Series.\")\n",
    "        if not isinstance(adj_close_prices.index, pd.DatetimeIndex):\n",
    "            raise ValueError(\"Input Series must have a DatetimeIndex.\")\n",
    "\n",
    "        # Sort the index to ensure correct return calculation (oldest to newest)\n",
    "        adj_close_prices = adj_close_prices.sort_index()\n",
    "\n",
    "        # Calculate daily returns using pct_change()\n",
    "        returns = adj_close_prices.pct_change().dropna()  # Drop the first NaN value\n",
    "\n",
    "        return returns\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating returns: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_stock(df, ticker, risk_free_rate=0.0, output_debug_data=False):\n",
    "    \"\"\"\n",
    "    Analyzes a single stock's performance based on its adjusted close prices.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Pandas DataFrame containing stock data, including 'Adj Close' column.\n",
    "        ticker (str): The stock ticker symbol (e.g., 'NVDA').\n",
    "        risk_free_rate (float): The annualized risk-free rate. Default is 0.0.\n",
    "        output_debug_data (bool): If True, print Adj Close prices and returns (default: False).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the ticker as index and 'Sharpe Ratio', 'Sortino Ratio', and 'Omega Ratio' as columns.\n",
    "                       Returns None if there is an error.  Crucially changed to return None, not an empty dataframe.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract Adj Close prices for the specified ticker\n",
    "        adj_close_prices = df.loc[ticker]['Adj Close']\n",
    "\n",
    "        # Check if adj_close_prices is a Series\n",
    "        if not isinstance(adj_close_prices, pd.Series):\n",
    "             raise TypeError(f\"Expected a Pandas Series for Adj Close prices of {ticker}. Check that {ticker} exists in the DataFrame, and that 'Adj Close' is a valid column\")\n",
    "\n",
    "        # Calculate returns\n",
    "        returns_series = calculate_returns(adj_close_prices)\n",
    "\n",
    "        if returns_series is not None:\n",
    "            # Output debug data if requested\n",
    "            if output_debug_data:\n",
    "                print(f\"--- Debug Data for {ticker} ---\")\n",
    "                print(\"\\nAdj Close Prices (Dates and Values):\")\n",
    "                print(adj_close_prices)  #This is a Series, prints the index(dates) and values.\n",
    "                print(\"\\nReturns:\")\n",
    "                print(returns_series)\n",
    "\n",
    "            # Calculate performance metrics\n",
    "            performance_metrics = calculate_performance_metrics(returns_series, risk_free_rate=risk_free_rate)\n",
    "\n",
    "            if performance_metrics:\n",
    "                # Create a DataFrame from the metrics\n",
    "                metrics_df = pd.DataFrame(performance_metrics, index=[ticker])\n",
    "                return metrics_df\n",
    "            else:\n",
    "                print(f\"Could not calculate performance metrics for {ticker}.\")\n",
    "                return None  # Return None, not an empty DataFrame\n",
    "        else:\n",
    "            print(f\"Failed to calculate returns for {ticker}.\")\n",
    "            return None # Return None, not an empty DataFrame\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"Ticker '{ticker}' not found in DataFrame.\")\n",
    "        return None # Return None, not an empty DataFrame\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during analysis: {e}\")\n",
    "        return None # Return None, not an empty DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>Sortino Ratio</th>\n",
       "      <th>Omega Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.969964</td>\n",
       "      <td>1.38213</td>\n",
       "      <td>1.175341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sharpe Ratio  Sortino Ratio  Omega Ratio\n",
       "NVDA      0.969964        1.38213     1.175341"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_stock(df, 'NVDA', risk_free_rate, output_debug_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance metrics DataFrame for NVDA:\n",
      "      Sharpe Ratio  Sortino Ratio  Omega Ratio\n",
      "NVDA      0.969964        1.38213     1.175341\n"
     ]
    }
   ],
   "source": [
    "# Analyze a single stock\n",
    "ticker = 'NVDA'\n",
    "# risk_free_rate = 0.01  # Example risk-free rate\n",
    "\n",
    "result_df = analyze_stock(df, ticker, risk_free_rate=risk_free_rate)\n",
    "if result_df is not None:  # Correctly check for None\n",
    "    print(f\"\\nPerformance metrics DataFrame for {ticker}:\")\n",
    "    print(result_df)\n",
    "else:\n",
    "    print(f\"\\nCould not calculate performance metrics for {ticker}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'ABBV', 'ABNB', 'ABT', 'ACN', 'ADBE', 'ADI', 'ADP', 'ADSK', 'AJG', 'AMAT', 'AMD', 'AMGN', 'AMT', 'AMZN', 'ANET', 'AON', 'APD', 'APH', 'APO', 'APP', 'ARM', 'ASML', 'AVGO', 'AXP', 'AZN', 'AZO', 'BABA', 'BAC', 'BAM', 'BCS', 'BDX', 'BK', 'BKNG', 'BLK', 'BMO', 'BNS', 'BP', 'BSX', 'BTI', 'BUD', 'BX', 'C', 'CDNS', 'CEG', 'CHTR', 'CI', 'CL', 'CM', 'CME', 'CMG', 'CNI', 'COF', 'COP', 'COST', 'CP', 'CRH', 'CRM', 'CRWD', 'CSX', 'CTAS', 'CVS', 'CVX', 'DASH', 'DELL', 'DHR', 'DIS', 'DUK', 'ECL', 'ELV', 'EMR', 'ENB', 'EPD', 'EQIX', 'EQNR', 'ET', 'ETN', 'FDX', 'FI', 'FTNT', 'GD', 'GE', 'GEV', 'GILD', 'GOOG', 'GOOGL', 'GS', 'GSK', 'HCA', 'HDB', 'HLT', 'HON', 'IBKR', 'IBM', 'IBN', 'ICE', 'INTU', 'ISRG', 'JD', 'JNJ', 'JPM', 'KKR', 'KLAC', 'KMI', 'KO', 'LIN', 'LLY', 'LMT', 'LOW', 'LRCX', 'MA', 'MAR', 'MCD', 'MCK', 'MCO', 'MDT', 'MELI', 'MET', 'META', 'MFG', 'MMC', 'MMM', 'MO', 'MRK', 'MS', 'MSFT', 'MSI', 'MU', 'MUFG', 'NEE', 'NFLX', 'NOC', 'NOW', 'NTES', 'NVDA', 'NVO', 'NVS', 'OKE', 'ORCL', 'ORLY', 'PANW', 'PDD', 'PEP', 'PG', 'PGR', 'PH', 'PLTR', 'PM', 'PNC', 'PYPL', 'QCOM', 'RACE', 'RCL', 'RELX', 'ROP', 'RSG', 'RTX', 'RY', 'SAN', 'SAP', 'SCCO', 'SCHW', 'SE', 'SHOP', 'SHW', 'SLB', 'SMFG', 'SNPS', 'SNY', 'SO', 'SONY', 'SPGI', 'SPOT', 'SYK', 'TDG', 'TFC', 'TJX', 'TMO', 'TMUS', 'TRI', 'TSLA', 'TSM', 'TT', 'TTE', 'TXN', 'UBS', 'UL', 'UNH', 'UNP', 'UPS', 'USB', 'V', 'VZ', 'WDAY', 'WELL', 'WFC', 'WM', 'WMB', 'WMT', 'ZTS']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve tickers from the file into a list\n",
    "tickers = []\n",
    "with open('tickers.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        tickers.append(line.strip())\n",
    "\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined performance metrics DataFrame:\n",
      "      Sharpe Ratio  Sortino Ratio  Omega Ratio\n",
      "AAPL      1.220949       1.826844     1.236133\n",
      "ABBV      0.744732       0.995488     1.153213\n",
      "ABNB     -0.328764      -0.448952     0.939889\n",
      "ABT       0.791461       1.222935     1.145934\n",
      "ACN      -0.337535      -0.460173     0.938945\n",
      "...            ...            ...          ...\n",
      "WFC       1.341553       2.204764     1.287815\n",
      "WM        0.630657       0.866401     1.132698\n",
      "WMB       2.221235       3.259412     1.466137\n",
      "WMT       2.604496       4.336011     1.606503\n",
      "ZTS      -0.537786      -0.722450     0.910585\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Analyze all stocks in the DataFrame and concatenate the results\n",
    "all_results = []\n",
    "# for ticker in df.columns.levels[0]: #get unique tickers\n",
    "for ticker in tickers: \n",
    "    result_df = analyze_stock(df, ticker, risk_free_rate=risk_free_rate)\n",
    "    if result_df is not None: # Correctly check for None\n",
    "        all_results.append(result_df)\n",
    "\n",
    "if all_results:\n",
    "    combined_df = pd.concat(all_results)\n",
    "    print(\"\\nCombined performance metrics DataFrame:\")\n",
    "    print(combined_df)\n",
    "else:\n",
    "    print(\"No performance metrics were calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame pickled successfully to performance_ratios.pkl\n"
     ]
    }
   ],
   "source": [
    "fn_performance_ratios = 'performance_ratios.pkl'\n",
    "combined_df.to_pickle(fn_performance_ratios)\n",
    "print(f\"DataFrame pickled successfully to {fn_performance_ratios}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.read_pickle(fn_performance_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sharpe Ratio     0.969964\n",
       "Sortino Ratio    1.382130\n",
       "Omega Ratio      1.175341\n",
       "Name: NVDA, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.loc['NVDA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity Check on calculation for: Sharpe Ratio, Sortino Ratio, Omega Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Santity check for NVDA ratios:\n",
      "{'Sharpe Ratio': 0.9699636443948492, 'Sortino Ratio': 1.3821304890461559, 'Omega Ratio': 1.175340985431688}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_ratios(daily_close, risk_free_rate=0.02, debug=False):\n",
    "    \"\"\"\n",
    "    Calculate risk-adjusted performance metrics from daily price data.\n",
    "    \n",
    "    Parameters:\n",
    "        daily_close (pd.Series): Series of daily closing prices with DatetimeIndex\n",
    "        risk_free_rate (float): Annualized risk-free rate (default: 0.02)\n",
    "        debug (bool): Whether to print intermediate calculations (default: False)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing Sharpe, Sortino, and Omega ratios\n",
    "    \"\"\"\n",
    "    # Validate and sort input\n",
    "    if not isinstance(daily_close, pd.Series):\n",
    "        raise TypeError(\"Input must be a pandas Series\")\n",
    "        \n",
    "    # Sort by date (oldest first) to ensure proper return calculations\n",
    "    sorted_series = daily_close.sort_index(ascending=True)\n",
    "    \n",
    "    # Calculate daily returns from closing prices\n",
    "    returns = sorted_series.pct_change().dropna()\n",
    "    if returns.empty:\n",
    "        raise ValueError(\"Insufficient data to calculate returns\")\n",
    "    \n",
    "    # Common parameters\n",
    "    days_per_year = 252\n",
    "    daily_risk_free = risk_free_rate / days_per_year\n",
    "    \n",
    "    # Initialize results storage\n",
    "    results = {}\n",
    "    debug_info = {\n",
    "        'sorted_dates': sorted_series.index,\n",
    "        'returns': returns\n",
    "    }\n",
    "\n",
    "    # Calculate Sharpe Ratio\n",
    "    avg_daily_return = returns.mean()\n",
    "    daily_std = returns.std()\n",
    "    sharpe_excess = avg_daily_return - daily_risk_free\n",
    "    results['Sharpe Ratio'] = (sharpe_excess / daily_std) * np.sqrt(days_per_year)\n",
    "    \n",
    "    # Store debug information\n",
    "    debug_info.update({\n",
    "        'avg_daily_return': avg_daily_return,\n",
    "        'daily_std': daily_std,\n",
    "        'sharpe_excess': sharpe_excess\n",
    "    })\n",
    "\n",
    "    # Calculate Sortino Ratio\n",
    "    excess_returns = returns - daily_risk_free\n",
    "    downside_returns = excess_returns[excess_returns < 0]\n",
    "    downside_std = np.sqrt(np.sum(downside_returns**2) / len(excess_returns))\n",
    "    results['Sortino Ratio'] = (excess_returns.mean() / downside_std) * np.sqrt(days_per_year)\n",
    "    \n",
    "    # Store debug information\n",
    "    debug_info.update({\n",
    "        'excess_returns': excess_returns,\n",
    "        'downside_returns': downside_returns,\n",
    "        'downside_std': downside_std\n",
    "    })\n",
    "\n",
    "    # Calculate Omega Ratio\n",
    "    threshold = daily_risk_free\n",
    "    returns_above = returns[returns > threshold]\n",
    "    returns_below = returns[returns <= threshold]\n",
    "    \n",
    "    sum_above = (returns_above - threshold).sum()\n",
    "    sum_below = (threshold - returns_below).sum()\n",
    "    \n",
    "    try:\n",
    "        results['Omega Ratio'] = sum_above / sum_below\n",
    "    except ZeroDivisionError:\n",
    "        results['Omega Ratio'] = np.nan\n",
    "    \n",
    "    # Store debug information\n",
    "    debug_info.update({\n",
    "        'threshold': threshold,\n",
    "        'sum_above': sum_above,\n",
    "        'sum_below': sum_below\n",
    "    })\n",
    "\n",
    "    if debug:\n",
    "        print(\"\\n=== Debug Information ===\")\n",
    "        print(f\"First 5 sorted dates: {debug_info['sorted_dates'][:5].strftime('%Y-%m-%d').tolist()}\")\n",
    "        print(f\"Last 5 sorted dates: {debug_info['sorted_dates'][-5:].strftime('%Y-%m-%d').tolist()}\")\n",
    "        print(f\"Number of trading days: {len(returns)}\")\n",
    "        print(f\"\\nSharpe Ratio Components:\")\n",
    "        print(f\"Average Daily Return: {debug_info['avg_daily_return']:.6f}\")\n",
    "        print(f\"Daily Std Dev: {debug_info['daily_std']:.6f}\")\n",
    "        print(f\"Daily Risk-Free Rate: {daily_risk_free:.6f}\")\n",
    "        print(f\"Sharpe Excess Return: {debug_info['sharpe_excess']:.6f}\")\n",
    "        \n",
    "        print(f\"\\nSortino Ratio Components:\")\n",
    "        print(f\"Excess Returns Mean: {excess_returns.mean():.6f}\")\n",
    "        print(f\"Downside Returns Count: {len(debug_info['downside_returns'])}\")\n",
    "        print(f\"Downside Std Dev: {debug_info['downside_std']:.6f}\")\n",
    "        \n",
    "        print(f\"\\nOmega Ratio Components:\")\n",
    "        print(f\"Threshold: {debug_info['threshold']:.6f}\")\n",
    "        print(f\"Returns Above Threshold: {len(returns_above)}\")\n",
    "        print(f\"Returns Below Threshold: {len(returns_below)}\")\n",
    "        print(f\"Sum Above Threshold: {debug_info['sum_above']:.6f}\")\n",
    "        print(f\"Sum Below Threshold: {debug_info['sum_below']:.6f}\")\n",
    "        print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Check calculation on NVDA ratios\n",
    "adj_close_series = df.loc['NVDA']['Adj Close']\n",
    "adj_close_series\n",
    "\n",
    "ratios = calculate_ratios(adj_close_series, risk_free_rate, debug=False)\n",
    "print(f'Santity check for NVDA ratios:\\n{ratios}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# def save_returns_to_csv(returns, filename=\"returns.csv\"):\n",
    "#     \"\"\"\n",
    "#     Saves a Pandas Series of returns to a CSV file in the user's Downloads directory.\n",
    "\n",
    "#     Args:\n",
    "#         returns (pd.Series): The Pandas Series containing the returns data.  The index is assumed to be dates.\n",
    "#         filename (str, optional): The name of the CSV file to create. Defaults to \"returns.csv\".\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Get the user's Downloads directory\n",
    "#     downloads_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "\n",
    "#     # Construct the full file path\n",
    "#     file_path = os.path.join(downloads_path, filename)\n",
    "\n",
    "#     try:\n",
    "#         # Write the Series to a CSV file\n",
    "#         returns.to_csv(file_path, header=True)  # Include header for column name\n",
    "\n",
    "#         print(f\"Returns data saved to: {file_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error saving returns to CSV: {e}\")\n",
    "\n",
    "\n",
    "# # Example Usage (replace with your actual returns Series)\n",
    "# # Create sample data\n",
    "# import numpy as np\n",
    "# dates = pd.to_datetime(pd.date_range('2023-01-01', periods=252))\n",
    "# returns = pd.Series(np.random.normal(0.0005, 0.01, 252), index=dates, name=\"Daily Return\") # important to give series a name!\n",
    "\n",
    "# # Save the data\n",
    "# save_returns_to_csv(returns, filename=\"my_returns_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
