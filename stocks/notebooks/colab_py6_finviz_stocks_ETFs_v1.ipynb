{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===== TURN ON POWERTOY AWAKE to KEEP CONNECTION ALIVE =====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install fake-useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "selector = '.styled-table-new'\n",
    "ua = UserAgent()  # Initialize UserAgent\n",
    "\n",
    "def download_table(url, selector):\n",
    "    \"\"\"\n",
    "    Downloads table data from a Yahoo Finance page with rate limiting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add a User-Agent header to mimic a browser\n",
    "        # headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}  # Example User-Agent\n",
    "        new_user_agent = ua.random\n",
    "        headers = {\"User-Agent\": new_user_agent}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table_body = soup.select_one(selector)\n",
    "\n",
    "        if table_body is None:\n",
    "            print(f\"Error: Table body not found using selector: {selector}\")\n",
    "            return None\n",
    "\n",
    "        rows = table_body.find_all('tr')\n",
    "        if not rows:\n",
    "            print(\"Error: No rows found in the table.\")\n",
    "            return None\n",
    "\n",
    "        # Extract headers from the first row (th elements)\n",
    "        headers_list = [th.text.strip() for th in rows[0].find_all('th')]\n",
    "\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            if row_data:  # Only append if the row has data\n",
    "                data.append(row_data)\n",
    "\n",
    "        if not data:\n",
    "            print(\"Error: No data found in the table rows.\")\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(data, columns=headers_list)\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during request: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_common_stock_etfs_metrics_sector_industry_category = 'c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66,103,100,109'\n",
    "columns_common_stock_etfs_metrics = 'c=0,1,2,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66,100,109'                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_mktcap ='https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c='\n",
    "# url_columns is 'columns_common_stock_etfs_metrics_sector_industry_category'\n",
    "url_columns = '0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66,103,100,109'\n",
    "url_mktcap_rows = ['&r=1', '&r=21', '&r=41', '&r=61', '&r=81', '&r=101', '&r=121', '&r=141', '&r=161', '&r=181', '&r=201', '&r=221', '&r=241', '&r=261', '&r=281', '&r=301', '&r=321', '&r=341', '&r=361', '&r=381', '&r=401', '&r=421', '&r=441', '&r=461', '&r=481', '&r=501', '&r=521', '&r=541', '&r=561', '&r=581', '&r=601', '&r=621', '&r=641', '&r=661', '&r=681', '&r=701', '&r=721', '&r=741', '&r=761', '&r=781', '&r=801', '&r=821', '&r=841', '&r=861', '&r=881', '&r=901', '&r=921', '&r=941', '&r=961', '&r=981']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_mktcap = []\n",
    "\n",
    "for _rows in url_mktcap_rows:\n",
    "    url = url_mktcap + url_columns + _rows\n",
    "    urls_mktcap.append(url)\n",
    "\n",
    "print(f'len(urls_mktcap): {len(urls_mktcap)}')\n",
    "print(urls_mktcap[0:3])  # Print the length of the list of url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_etfs ='https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c='\n",
    "url_etfs_rows = ['&r=1', '&r=21', '&r=41', '&r=61', '&r=81', '&r=101', '&r=121', '&r=141', '&r=161', '&r=181', '&r=201', '&r=221', '&r=241', '&r=261', '&r=281', '&r=301', '&r=321', '&r=341', '&r=361', '&r=381']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_etfs = []\n",
    "\n",
    "for _rows in url_etfs_rows:\n",
    "    url = url_etfs + url_columns + _rows\n",
    "    urls_etfs.append(url)\n",
    "\n",
    "print(f'len(urls_etfs): {len(urls_etfs)}')\n",
    "print(urls_etfs[0:3])  # Print the length of the list of url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "urls =  urls_mktcap + urls_etfs\n",
    "shuffled_urls = random.sample(urls, len(urls))\n",
    "print(f'len(shuffled_urls): {len(shuffled_urls)}') \n",
    "print(f'shuffled_urls[0:10]')\n",
    "for url in shuffled_urls[0:10]:\n",
    "    print(f'{url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_urls = [\n",
    "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=1',\n",
    "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-e.assetsundermanagement&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=101',\n",
    "#   'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=601',\n",
    "#   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "total_urls_to_download = len(shuffled_urls)\n",
    "\n",
    "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
    "processed_count = 0\n",
    "\n",
    "columns_list = ['No.', 'Ticker', 'Company', 'Sector', 'Industry', 'Market Cap',\n",
    "       'Dividend', 'Perf Week', 'Perf Month', 'Perf Quart', 'Perf Half',\n",
    "       'Perf Year', 'Perf YTD', 'Beta', 'ATR', 'Volatility W', 'Volatility M',\n",
    "       'SMA20', 'SMA50', 'SMA200', '50D High', '50D Low', '52W High',\n",
    "       '52W Low', 'All-Time High', 'All-Time Low', 'RSI', 'Gap', 'Avg Volume',\n",
    "       'Rel Volume', 'Volume', 'Price', 'Change', 'Single Category',\n",
    "       'Asset Type', 'AUM']\n",
    "\n",
    "# for url in test_urls:\n",
    "for url in shuffled_urls[3:6]:\n",
    "    # Introduce a delay between requests (adjust as needed)\n",
    "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
    "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
    "    processed_count += 1\n",
    "    print(f\"Downloading {url}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_urls_to_download} urls\")\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    df_temp = download_table(url, selector)\n",
    "\n",
    "    if df_temp is not None:\n",
    "        df_temp_filtered = df_temp[columns_list]\n",
    "        # Discards the original row indices of both DataFrames.\n",
    "        # Creates a new sequential integer index\n",
    "        df = pd.concat([df, df_temp_filtered], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Failed to download data for {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "pst = pytz.timezone('America/Los_Angeles')  # or 'US/Pacific'\n",
    "current_date_pst = datetime.datetime.now(pst).strftime('%Y-%m-%d')\n",
    "\n",
    "df_finviz_filename = f\"df_finviz_{current_date_pst}.pkl\"\n",
    "\n",
    "print(f\"df_finviz_filename: {df_finviz_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a pickle file\n",
    "df.to_pickle(df_finviz_filename)  # Saves to the Colab's runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: pickle df and download to my pc\n",
    "\n",
    "import pickle\n",
    "from google.colab import files\n",
    "\n",
    "# Download the pickle file\n",
    "files.download(df_finviz_filename)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0Xbj8MojxCBwCH1wY3vgo",
   "mount_file_id": "1kPgpF6IeYD0Y-AVWLPiZ92O5i60rq7nT",
   "provenance": [
    {
     "file_id": "1IwwL6zZA9L74r4-OPTkHxJhLYSyUzc7V",
     "timestamp": 1741059324768
    },
    {
     "file_id": "1Kysq6BVvqd3O84m0gdT3BQm0jVwlp4XD",
     "timestamp": 1740622053247
    },
    {
     "file_id": "1XL4-86ZLWu8UIMKO6GL97YMbIdSslX5K",
     "timestamp": 1740587177316
    },
    {
     "file_id": "1KXs8MumJ78xO9mcgU8bnQwtev1ZYwIGm",
     "timestamp": 1740372106860
    },
    {
     "file_id": "19kXxHAiFbW12PG4kbS8SPisFq7mbgVQh",
     "timestamp": 1740371261418
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
