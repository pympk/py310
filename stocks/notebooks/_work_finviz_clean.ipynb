{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common metrics Stock & ETFs <br> \n",
    "https://finviz.com/screener.ashx?v=152&o=-marketcap&c=0,1,6,42,43,44,45,46,47,52,53,54,55,56,67,65,66,109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_columns = '0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122'\n",
    "new_columns = '0,1,6,42,43,44,45,46,47,52,53,54,55,56,67,65,66,109'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_common_stock_etfs_metrics_sector_industry_category = 'c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66,103,100,109'\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_common_stock_etfs_metrics = 'c=0,1,2,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66,100,109'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://finviz.com/screener.ashx?v=152&o=marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,125,126,59,61,63,64,67,65,66,103,100,109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined columns: 0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,65,66,67,100,103,109,120,121,122\n"
     ]
    }
   ],
   "source": [
    "# Split strings into lists and convert to integers\n",
    "url_nums = [int(x) for x in url_columns.split(',')]\n",
    "new_nums = [int(x) for x in new_columns.split(',')]\n",
    "\n",
    "# Combine lists, convert to set for uniqueness, sort\n",
    "combined_nums = sorted(set(url_nums + new_nums))\n",
    "\n",
    "# Convert back to comma-separated string\n",
    "combined_str = ','.join(str(x) for x in combined_nums)\n",
    "print(f\"Combined columns: {combined_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,65,66,67,100,103,109,120,121,122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://finviz.com/screener.ashx?v=152&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,65,66,67,100,103,109,120,121,122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://finviz.com/screener.ashx?v=152&o=-marketcap&c=0,1,6,42,43,44,45,46,47,52,53,54,55,56,67,65,66,109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Notebook cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Get root directory (assuming notebook is in root/notebooks/)\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "ROOT_DIR = NOTEBOOK_DIR.parent if NOTEBOOK_DIR.name == 'notebooks' else NOTEBOOK_DIR\n",
    "\n",
    "# Add src directory to Python path\n",
    "sys.path.append(str(ROOT_DIR / 'src'))\n",
    "\n",
    "# Verify path\n",
    "print(f\"Python will look in these locations:\\n{sys.path}\")\n",
    "\n",
    "\n",
    "# --- Execute the processor ---\n",
    "import utils\n",
    "\n",
    "# SOURCE_PATH_OHLCV = '..\\data\\df_OHLCV_2025-03-07_clean.pkl'\n",
    "# SOURCE_PATH_STOCK = '..\\data\\df_finviz_stocks_n_ratios.pkl'\n",
    "# SOURCE_PATH_ETF = '..\\data\\df_finviz_etfs_n_ratios.pkl'\n",
    "\n",
    "SOURCE_PATH, DEST_PATH = utils.main_processor(\n",
    "    data_dir='..\\data',  # search project ..\\data\n",
    "    downloads_dir=None,  # None searchs Downloads dir, '' omits search\n",
    "    downloads_limit=10,  # search the first 10 files\n",
    "    clean_name_override='df_finviz_cleaned',  # override filename\n",
    "    start_file_pattern='df_finviz_', # search for files starting with 'df_'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(SOURCE_PATH)\n",
    "# df_etfs = pd.read_pickle(SOURCE_PATH_ETF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in Ticker column\n",
    "duplicates = df[df['Ticker'].duplicated(keep=False)]\n",
    "if len(duplicates) > 0:\n",
    "  print(\"Duplicate tickers found:\")\n",
    "  print(duplicates[['Ticker', 'Company']])\n",
    "else:\n",
    "  print(\"No duplicate tickers found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('No.', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Ticker', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df.head())\n",
    "# display(df.tail())\n",
    "display(df.loc['AAPL'], df.loc['SPY'])\n",
    "# display(df.loc['SPY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etfs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get common columns between stocks and ETFs dataframes\n",
    "common_columns = set(df_stocks.columns).intersection(set(df_etfs.columns))\n",
    "\n",
    "# Convert to sorted list for better readability\n",
    "common_columns = sorted(list(common_columns))\n",
    "\n",
    "print(f\"Number of common columns: {len(common_columns)}\")\n",
    "print(\"\\nCommon columns:\")\n",
    "for col in common_columns:\n",
    "  print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_df = pd.read_pickle(SOURCE_PATH_STOCK)\n",
    "df_stocks = _df.iloc[0:100].copy()\n",
    "display(df_stocks.info())\n",
    "\n",
    "# Convert DataFrame to list of dictionaries with index as 'Ticker'\n",
    "records_stocks = df_stocks.reset_index().to_dict('records')\n",
    "\n",
    "# Convert to string representation\n",
    "records_stocks_str = str(records_stocks)\n",
    "\n",
    "# Print first 1000 characters to preview\n",
    "display(records_stocks_str[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_df = pd.read_pickle('..\\data\\df_finviz_etfs_n_ratios.pkl')\n",
    "df_etfs = _df.iloc[0:40].copy()\n",
    "display(df_etfs.info())\n",
    "\n",
    "# Convert DataFrame to list of dictionaries with index as 'Ticker'\n",
    "records_etfs = df_etfs.reset_index().to_dict('records')\n",
    "\n",
    "# Convert to string representation\n",
    "records_etfs_str = str(records_etfs)\n",
    "\n",
    "# Print first 1000 characters to preview\n",
    "display(records_etfs_str[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine indexes from both dataframes into a single list of symbols\n",
    "symbols = list(df_stocks.index) + list(df_etfs.index)\n",
    "print(f\"Total number of symbols: {len(symbols)}\")\n",
    "print(f\"First 10 symbols: {symbols[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.read_pickle('..\\data\\df_correlation_matrix.pkl')\n",
    "display(_df)\n",
    "\n",
    "df_correlation = _df.loc[symbols, symbols]\n",
    "display(df_correlation)\n",
    "\n",
    "# Convert DataFrame to list of dictionaries with index as 'Ticker'\n",
    "records_correlation = df_correlation.reset_index().to_dict('records')\n",
    "\n",
    "# Convert to string representation\n",
    "records_correlation_str = str(records_correlation)\n",
    "\n",
    "# Print first 1000 characters to preview\n",
    "display(records_correlation_str[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the formatted string with triple quotes\n",
    "formatted_records = f'records_stocks = \"\"\"{records_stocks_str}\"\"\"'\n",
    "\n",
    "# Save to a file in the data directory\n",
    "output_path = Path(ROOT_DIR) / 'data' / 'records_stocks.txt'\n",
    "with open(output_path, 'w') as f:\n",
    "  f.write(formatted_records)\n",
    "\n",
    "print(f\"File saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the formatted string with triple quotes\n",
    "formatted_records = f'records_etfs = \"\"\"{records_etfs_str}\"\"\"'\n",
    "\n",
    "# Save to a file in the data directory\n",
    "output_path = Path(ROOT_DIR) / 'data' / 'records_etfs.txt'\n",
    "with open(output_path, 'w') as f:\n",
    "  f.write(formatted_records)\n",
    "\n",
    "print(f\"File saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the formatted string with triple quotes\n",
    "formatted_records = f'records_correlation = \"\"\"{records_correlation_str}\"\"\"'\n",
    "\n",
    "# Save to a file in the data directory\n",
    "output_path = Path(ROOT_DIR) / 'data' / 'records_correlation.txt'\n",
    "with open(output_path, 'w') as f:\n",
    "  f.write(formatted_records)\n",
    "\n",
    "print(f\"File saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you are a financial expert in stock trading, stock analysis, and building and managing financial portfolios.\n",
    "you are a financial expert in selecting stocks and ETFs to build a portfolio. your goal is to build a  portfolio with stocks and ETFs combination that will most likely to produce superior returns with acceptable risk for the each of the next 15, 30, 63, 125 trading days. user will give you financial data for stocks, ETFs and their Sharpe Ratio, Sortino Ratio, and Omega Ratio for the past 30, 63, 125, 250 trading days. User will also give you the correlation matrix of these stocks and ETFs for the past 250 trading days. your job is to select the stocks and ETFs for portfolio to produce superior returns with acceptable risk for the each of the next 15, 30, 63, 125 trading days. Please provide the allocation percentage for each symbols in the portfolio.\n",
    "\n",
    "Here is the user profile:\n",
    "Investor-Specific Risk Aversion Coefficient: 1.3 where 0 is aggressive and 5 is risk-averse\n",
    "Transaction Costs: 0.3%\n",
    "Tax: 0%\n",
    "Liquidity Needs: no need for future cash\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i will give you stocks, ETFs, correlation data. don't analyze the data, just look at it, and tell me do you understand the data. do you need clarification? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_pickle('../data/df_finviz_stocks_n_ratios.pkl')  # Use raw string or double backslashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Studio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from pypfopt import EfficientFrontier, objective_functions\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "def select_outperforming_stocks(df):\n",
    "    \"\"\"Stock selection with debug output\"\"\"\n",
    "    print(\"\\n=== Starting Stock Selection ===\")\n",
    "    \n",
    "    # Handle Ticker position\n",
    "    if df.index.name == 'Ticker':\n",
    "        temp_df = df.reset_index()\n",
    "        print(\"Reset Ticker index to column\")\n",
    "    else:\n",
    "        temp_df = df.copy()\n",
    "        print(\"Ticker already in columns\")\n",
    "\n",
    "    # Validate required columns\n",
    "    required_cols = {\n",
    "        'Ticker', 'Sharpe 30d', 'Sortino 30d', 'Omega 30d',\n",
    "        'Sharpe 63d', 'Sortino 63d', 'Omega 63d', 'Sharpe 125d',\n",
    "        'Sortino 125d', 'Omega 125d', 'EPS next Y', 'Profit M',\n",
    "        'PEG', 'Beta', 'Inst Own', 'Recom', 'Volatility M'\n",
    "    }\n",
    "    missing = required_cols - set(temp_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    \n",
    "    print(f\"Processing {len(temp_df)} stocks\")\n",
    "\n",
    "    # Horizon configuration\n",
    "    horizons = {\n",
    "        15: '30d',\n",
    "        30: '30d', \n",
    "        60: '63d',\n",
    "        120: '125d'\n",
    "    }\n",
    "\n",
    "    selected_stocks = {}\n",
    "    \n",
    "    for days, suffix in horizons.items():\n",
    "        print(f\"\\n-- Analyzing {days}-day horizon --\")\n",
    "        sharpe = f'Sharpe {suffix}'\n",
    "        sortino = f'Sortino {suffix}'\n",
    "        omega = f'Omega {suffix}'\n",
    "        \n",
    "        # Filter stocks\n",
    "        valid = temp_df[\n",
    "            (temp_df[sharpe] > 0) &\n",
    "            (temp_df[sortino] > 0) &\n",
    "            (temp_df[omega] > 1)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"Found {len(valid)} qualifying stocks\")\n",
    "        \n",
    "        if valid.empty:\n",
    "            selected_stocks[f'{days}_days'] = []\n",
    "            continue\n",
    "\n",
    "        # Scoring metrics\n",
    "        scoring = [\n",
    "            (sharpe, 1.5, False),\n",
    "            (sortino, 1.5, False),\n",
    "            (omega, 1.2, False),\n",
    "            ('EPS next Y', 1.0, False),\n",
    "            ('Profit M', 0.8, False),\n",
    "            ('PEG', 0.7, True),\n",
    "            ('Beta', 0.7, True),\n",
    "            ('Inst Own', 0.5, False),\n",
    "            ('Recom', 0.5, True)\n",
    "        ]\n",
    "\n",
    "        # Calculate scores\n",
    "        for metric, weight, invert in scoring:\n",
    "            z_vals = zscore(valid[metric], nan_policy='omit')\n",
    "            z_vals = np.nan_to_num(z_vals, nan=0.0)\n",
    "            if invert:\n",
    "                z_vals = -z_vals\n",
    "            valid[f'{metric}_score'] = z_vals * weight\n",
    "\n",
    "        # Total score\n",
    "        score_cols = [f'{metric}_score' for metric, _, _ in scoring]\n",
    "        valid['total_score'] = valid[score_cols].sum(axis=1)\n",
    "        \n",
    "        # # Select top 5\n",
    "        # top_5 = valid.nlargest(5, 'total_score')['Ticker'].tolist()\n",
    "        # print(f\"Selected top 5: {top_5}\")\n",
    "        # selected_stocks[f'{days}_days'] = top_5[:5]\n",
    "\n",
    "        # Select top 100\n",
    "        top_100 = valid.nlargest(100, 'total_score')['Ticker'].tolist()\n",
    "        print(f\"Selected top 100: {top_100}\")\n",
    "        selected_stocks[f'{days}_days'] = top_100[:100]\n",
    "\n",
    "\n",
    "    return selected_stocks\n",
    "\n",
    "def optimize_portfolio(selected_tickers, df_metrics, df_correlation):\n",
    "    \"\"\"Portfolio optimization with debug output\"\"\"\n",
    "    print(\"\\n=== Starting Portfolio Optimization ===\")\n",
    "    \n",
    "    # Handle Ticker index\n",
    "    if df_metrics.index.name == 'Ticker':\n",
    "        metrics = df_metrics\n",
    "        print(\"Ticker index already set in metrics\")\n",
    "    else:\n",
    "        metrics = df_metrics.set_index('Ticker')\n",
    "        print(\"Set Ticker index in metrics\")\n",
    "\n",
    "    # Common tickers handling\n",
    "    common = list(set(selected_tickers) \n",
    "                  & set(df_correlation.index) \n",
    "                  & set(metrics.index))\n",
    "    \n",
    "    print(f\"Common tickers: {common}\")\n",
    "    \n",
    "    if not common:\n",
    "        raise ValueError(\"No common tickers between selection and correlation matrix\")\n",
    "    \n",
    "    # Prepare data\n",
    "    df_corr = df_correlation.loc[common, common]\n",
    "    df_sub = metrics.loc[common]\n",
    "    \n",
    "    # Calculate covariance matrix\n",
    "    print(\"\\nCalculating covariance matrix...\")\n",
    "    #volatilities = df_sub['Volatility M'] * np.sqrt(21)  # Monthly to annualized\n",
    "    #cov_matrix = pd.DataFrame(\n",
    "    #    np.outer(volatilities, volatilities) * df_corr.values,\n",
    "    #    index=common,\n",
    "    #    columns=common\n",
    "    #)\n",
    "\n",
    "    # Use sample covariance matrix directly from returns (more robust)\n",
    "    returns_data = df_metrics.loc[common, ['Sharpe 30d', 'Sharpe 63d', 'Sharpe 125d']].fillna(0) # Replace nan with 0, but a better approach could use more sophisticated imputation\n",
    "    sample_cov = risk_models.sample_cov(returns_data)\n",
    "    cov_matrix = pd.DataFrame(sample_cov, index=common, columns=common) # ensure correct indexing\n",
    "\n",
    "    \n",
    "    # Calculate expected returns\n",
    "    print(\"Calculating expected returns...\")\n",
    "    #df_sub['Expected Return'] = (\n",
    "    #    0.4 * df_sub['EPS next Y'] +\n",
    "    #    0.3 * df_sub['Profit M'] +\n",
    "    #    0.2 * df_sub['Sales Q/Q'] +\n",
    "    #    0.1 * (5 - df_sub['Recom'])  # Inverse since lower Recom is better\n",
    "    #)\n",
    "    \n",
    "    # Using mean historical return (less prone to errors)\n",
    "    #mu = expected_returns.mean_historical_return(df_metrics.loc[common, ['Sharpe 30d', 'Sharpe 63d', 'Sharpe 125d']].fillna(0))  # Replace nan with 0 for calculation\n",
    "    # expected_returns = mu\n",
    "    #df_sub['Expected Return'] = expected_returns\n",
    "    \n",
    "    #Using the mean of Sharpe Ratios as a proxy of expected returns\n",
    "    df_sub['Expected Return'] = df_sub[['Sharpe 30d', 'Sharpe 63d', 'Sharpe 125d']].mean(axis=1)\n",
    "    expected_returns = df_sub['Expected Return'].values  # Convert to numpy array\n",
    "    expected_returns = pd.Series(expected_returns, index=common)  # Ensure correct indexing\n",
    "\n",
    "\n",
    "    # Portfolio optimization\n",
    "    print(\"Optimizing portfolio...\")\n",
    "    ef = EfficientFrontier(\n",
    "        expected_returns=expected_returns, # Use the correctly indexed series\n",
    "        cov_matrix=cov_matrix,\n",
    "        weight_bounds=(0.02, 0.25)\n",
    "    )\n",
    "    ef.add_objective(objective_functions.L2_reg, gamma=0.1)\n",
    "    try:\n",
    "        ef.max_sharpe()\n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed: {e}\")\n",
    "        return {}  # Or some other appropriate handling\n",
    "\n",
    "    \n",
    "    weights = ef.clean_weights()\n",
    "    print(\"\\n=== Optimization Results ===\")\n",
    "    print(\"Portfolio weights:\")\n",
    "    for ticker, weight in weights.items():\n",
    "        print(f\"{ticker}: {weight:.2%}\")\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def full_analysis_pipeline(df_metrics, df_correlation):\n",
    "    \"\"\"Complete pipeline with debug output\"\"\"\n",
    "    print(\"=== Starting Full Analysis Pipeline ===\")\n",
    "    \n",
    "    # Ensure metrics has Ticker index\n",
    "    if df_metrics.index.name != 'Ticker':\n",
    "        df_metrics = df_metrics.set_index('Ticker')\n",
    "        print(\"Set Ticker index in metrics DataFrame\")\n",
    "    \n",
    "    # Step 1: Stock selection\n",
    "    selected = select_outperforming_stocks(df_metrics)\n",
    "    all_tickers = list(set(\n",
    "        t for horizon in selected.values() \n",
    "        for t in horizon if isinstance(t, str)\n",
    "        ))\n",
    "    \n",
    "    print(f\"\\nFinal selected tickers: {all_tickers}\")\n",
    "    \n",
    "    # Step 2: Portfolio optimization\n",
    "    if not all_tickers:\n",
    "        raise ValueError(\"No stocks selected in initial filtering\")\n",
    "        \n",
    "    return optimize_portfolio(all_tickers, df_metrics, df_correlation)\n",
    "\n",
    "# Usage example:\n",
    "# df_metrics = pd.read_pickle(r'..\\data\\df_finviz_stocks_n_ratios.pkl')\n",
    "# df_correlation = pd.read_csv('correlation_matrix.csv', index_col=0)\n",
    "# portfolio = full_analysis_pipeline(df_metrics, df_correlation)\n",
    "\n",
    "df_metrics = pd.read_pickle('..\\data\\df_finviz_stocks_n_ratios.pkl')\n",
    "\n",
    "_df = pd.read_pickle('..\\data\\df_correlation_matrix.pkl')\n",
    "df_correlation = _df.loc[symbols, symbols]\n",
    "\n",
    "portfolio = full_analysis_pipeline(df_metrics, df_correlation)\n",
    "portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Studio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from pypfopt import EfficientFrontier, objective_functions\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "def select_outperforming_stocks(df):\n",
    "    \"\"\"Stock selection with debug output\"\"\"\n",
    "    print(\"\\n=== Starting Stock Selection ===\")\n",
    "    \n",
    "    # Handle Ticker position\n",
    "    if df.index.name == 'Ticker':\n",
    "        temp_df = df.reset_index()\n",
    "        print(\"Reset Ticker index to column\")\n",
    "    else:\n",
    "        temp_df = df.copy()\n",
    "        print(\"Ticker already in columns\")\n",
    "\n",
    "    # Validate required columns\n",
    "    required_cols = {\n",
    "        'Ticker', 'Sharpe 30d', 'Sortino 30d', 'Omega 30d',\n",
    "        'Sharpe 63d', 'Sortino 63d', 'Omega 63d', 'Sharpe 125d',\n",
    "        'Sortino 125d', 'Omega 125d', 'EPS next Y', 'Profit M',\n",
    "        'PEG', 'Beta', 'Inst Own', 'Recom', 'Volatility M'\n",
    "    }\n",
    "    missing = required_cols - set(temp_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    \n",
    "    print(f\"Processing {len(temp_df)} stocks\")\n",
    "\n",
    "    # Horizon configuration\n",
    "    horizons = {\n",
    "        15: '30d',\n",
    "        30: '30d', \n",
    "        60: '63d',\n",
    "        120: '125d'\n",
    "    }\n",
    "\n",
    "    selected_stocks = {}\n",
    "    \n",
    "    for days, suffix in horizons.items():\n",
    "        print(f\"\\n-- Analyzing {days}-day horizon --\")\n",
    "        sharpe = f'Sharpe {suffix}'\n",
    "        sortino = f'Sortino {suffix}'\n",
    "        omega = f'Omega {suffix}'\n",
    "        \n",
    "        # Filter stocks\n",
    "        valid = temp_df[\n",
    "            (temp_df[sharpe] > 0) &\n",
    "            (temp_df[sortino] > 0) &\n",
    "            (temp_df[omega] > 1)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"Found {len(valid)} qualifying stocks\")\n",
    "        \n",
    "        if valid.empty:\n",
    "            selected_stocks[f'{days}_days'] = []\n",
    "            continue\n",
    "\n",
    "        # Scoring metrics\n",
    "        scoring = [\n",
    "            (sharpe, 1.5, False),\n",
    "            (sortino, 1.5, False),\n",
    "            (omega, 1.2, False),\n",
    "            ('EPS next Y', 1.0, False),\n",
    "            ('Profit M', 0.8, False),\n",
    "            ('PEG', 0.7, True),\n",
    "            ('Beta', 0.7, True),\n",
    "            ('Inst Own', 0.5, False),\n",
    "            ('Recom', 0.5, True)\n",
    "        ]\n",
    "\n",
    "        # Calculate scores\n",
    "        for metric, weight, invert in scoring:\n",
    "            z_vals = zscore(valid[metric], nan_policy='omit')\n",
    "            z_vals = np.nan_to_num(z_vals, nan=0.0)\n",
    "            if invert:\n",
    "                z_vals = -z_vals\n",
    "            valid[f'{metric}_score'] = z_vals * weight\n",
    "\n",
    "        # Total score\n",
    "        score_cols = [f'{metric}_score' for metric, _, _ in scoring]\n",
    "        valid['total_score'] = valid[score_cols].sum(axis=1)\n",
    "        \n",
    "        # Select top 5\n",
    "        top_5 = valid.nlargest(5, 'total_score')['Ticker'].tolist()\n",
    "        print(f\"Selected top 5: {top_5}\")\n",
    "        selected_stocks[f'{days}_days'] = top_5[:5]\n",
    "\n",
    "    return selected_stocks\n",
    "\n",
    "def optimize_portfolio(selected_tickers, df_metrics, df_correlation):\n",
    "    \"\"\"Portfolio optimization with debug output\"\"\"\n",
    "    print(\"\\n=== Starting Portfolio Optimization ===\")\n",
    "    \n",
    "    # Handle Ticker index\n",
    "    if df_metrics.index.name == 'Ticker':\n",
    "        metrics = df_metrics\n",
    "        print(\"Ticker index already set in metrics\")\n",
    "    else:\n",
    "        metrics = df_metrics.set_index('Ticker')\n",
    "        print(\"Set Ticker index in metrics\")\n",
    "\n",
    "    # Common tickers handling\n",
    "    common = list(set(selected_tickers) \n",
    "                  & set(df_correlation.index) \n",
    "                  & set(metrics.index))\n",
    "    \n",
    "    print(f\"Common tickers: {common}\")\n",
    "    \n",
    "    if not common:\n",
    "        raise ValueError(\"No common tickers between selection and correlation matrix\")\n",
    "    \n",
    "    # Prepare data\n",
    "    df_corr = df_correlation.loc[common, common]\n",
    "    df_sub = metrics.loc[common]\n",
    "    \n",
    "    # Calculate covariance matrix\n",
    "    print(\"\\nCalculating covariance matrix...\")\n",
    "    #volatilities = df_sub['Volatility M'] * np.sqrt(21)  # Monthly to annualized\n",
    "    #cov_matrix = pd.DataFrame(\n",
    "    #    np.outer(volatilities, volatilities) * df_corr.values,\n",
    "    #    index=common,\n",
    "    #    columns=common\n",
    "    #)\n",
    "\n",
    "    # Use sample covariance matrix directly from returns (more robust)\n",
    "    returns_data = df_metrics.loc[common, ['Sharpe 30d', 'Sharpe 63d', 'Sharpe 125d']].fillna(0) # Replace nan with 0, but a better approach could use more sophisticated imputation\n",
    "    sample_cov = risk_models.sample_cov(returns_data)\n",
    "    cov_matrix = sample_cov\n",
    "\n",
    "\n",
    "    \n",
    "    # Calculate expected returns\n",
    "    print(\"Calculating expected returns...\")\n",
    "    #df_sub['Expected Return'] = (\n",
    "    #    0.4 * df_sub['EPS next Y'] +\n",
    "    #    0.3 * df_sub['Profit M'] +\n",
    "    #    0.2 * df_sub['Sales Q/Q'] +\n",
    "    #    0.1 * (5 - df_sub['Recom'])  # Inverse since lower Recom is better\n",
    "    #)\n",
    "    \n",
    "    # Using mean historical return (less prone to errors)\n",
    "    #mu = expected_returns.mean_historical_return(df_metrics.loc[common, ['Sharpe 30d', 'Sharpe 63d', 'Sharpe 125d']].fillna(0))  # Replace nan with 0 for calculation\n",
    "    # expected_returns = mu\n",
    "    #df_sub['Expected Return'] = expected_returns\n",
    "    \n",
    "    #Using the mean of Sharpe Ratios as a proxy of expected returns\n",
    "    df_sub['Expected Return'] = df_sub[['Sharpe 30d', 'Sharpe 63d', 'Sharpe 125d']].mean(axis=1)\n",
    "\n",
    "\n",
    "    # Portfolio optimization\n",
    "    print(\"Optimizing portfolio...\")\n",
    "    ef = EfficientFrontier(\n",
    "        expected_returns=df_sub['Expected Return'],\n",
    "        cov_matrix=cov_matrix,\n",
    "        weight_bounds=(0.02, 0.25)\n",
    "    )\n",
    "    ef.add_objective(objective_functions.L2_reg, gamma=0.1)\n",
    "    try:\n",
    "        ef.max_sharpe()\n",
    "    except Exception as e:\n",
    "        print(f\"Optimization failed: {e}\")\n",
    "        return {}  # Or some other appropriate handling\n",
    "\n",
    "    \n",
    "    weights = ef.clean_weights()\n",
    "    print(\"\\n=== Optimization Results ===\")\n",
    "    print(\"Portfolio weights:\")\n",
    "    for ticker, weight in weights.items():\n",
    "        print(f\"{ticker}: {weight:.2%}\")\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def full_analysis_pipeline(df_metrics, df_correlation):\n",
    "    \"\"\"Complete pipeline with debug output\"\"\"\n",
    "    print(\"=== Starting Full Analysis Pipeline ===\")\n",
    "    \n",
    "    # Ensure metrics has Ticker index\n",
    "    if df_metrics.index.name != 'Ticker':\n",
    "        df_metrics = df_metrics.set_index('Ticker')\n",
    "        print(\"Set Ticker index in metrics DataFrame\")\n",
    "    \n",
    "    # Step 1: Stock selection\n",
    "    selected = select_outperforming_stocks(df_metrics)\n",
    "    all_tickers = list(set(\n",
    "        t for horizon in selected.values() \n",
    "        for t in horizon if isinstance(t, str)\n",
    "        ))\n",
    "    \n",
    "    print(f\"\\nFinal selected tickers: {all_tickers}\")\n",
    "    \n",
    "    # Step 2: Portfolio optimization\n",
    "    if not all_tickers:\n",
    "        raise ValueError(\"No stocks selected in initial filtering\")\n",
    "        \n",
    "    return optimize_portfolio(all_tickers, df_metrics, df_correlation)\n",
    "\n",
    "# Usage example:\n",
    "# df_metrics = pd.read_pickle(r'..\\data\\df_finviz_stocks_n_ratios.pkl')\n",
    "# df_correlation = pd.read_csv('correlation_matrix.csv', index_col=0)\n",
    "# portfolio = full_analysis_pipeline(df_metrics, df_correlation)\n",
    "\n",
    "df_metrics = pd.read_pickle('..\\data\\df_finviz_stocks_n_ratios.pkl')\n",
    "\n",
    "_df = pd.read_pickle('..\\data\\df_correlation_matrix.pkl')\n",
    "df_correlation = _df.loc[symbols, symbols]\n",
    "\n",
    "portfolio = full_analysis_pipeline(df_metrics, df_correlation)\n",
    "portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from pypfopt import EfficientFrontier, objective_functions\n",
    "\n",
    "def select_outperforming_stocks(df):\n",
    "    \"\"\"Stock selection with debug output\"\"\"\n",
    "    print(\"\\n=== Starting Stock Selection ===\")\n",
    "    \n",
    "    # Handle Ticker position\n",
    "    if df.index.name == 'Ticker':\n",
    "        temp_df = df.reset_index()\n",
    "        print(\"Reset Ticker index to column\")\n",
    "    else:\n",
    "        temp_df = df.copy()\n",
    "        print(\"Ticker already in columns\")\n",
    "\n",
    "    # Validate required columns\n",
    "    required_cols = {\n",
    "        'Ticker', 'Sharpe 30d', 'Sortino 30d', 'Omega 30d',\n",
    "        'Sharpe 63d', 'Sortino 63d', 'Omega 63d', 'Sharpe 125d',\n",
    "        'Sortino 125d', 'Omega 125d', 'EPS next Y', 'Profit M',\n",
    "        'PEG', 'Beta', 'Inst Own', 'Recom', 'Volatility M'\n",
    "    }\n",
    "    missing = required_cols - set(temp_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    \n",
    "    print(f\"Processing {len(temp_df)} stocks\")\n",
    "\n",
    "    # Horizon configuration\n",
    "    horizons = {\n",
    "        15: '30d',\n",
    "        30: '30d', \n",
    "        60: '63d',\n",
    "        120: '125d'\n",
    "    }\n",
    "\n",
    "    selected_stocks = {}\n",
    "    \n",
    "    for days, suffix in horizons.items():\n",
    "        print(f\"\\n-- Analyzing {days}-day horizon --\")\n",
    "        sharpe = f'Sharpe {suffix}'\n",
    "        sortino = f'Sortino {suffix}'\n",
    "        omega = f'Omega {suffix}'\n",
    "        \n",
    "        # Filter stocks\n",
    "        valid = temp_df[\n",
    "            (temp_df[sharpe] > 0) &\n",
    "            (temp_df[sortino] > 0) &\n",
    "            (temp_df[omega] > 1)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"Found {len(valid)} qualifying stocks\")\n",
    "        \n",
    "        if valid.empty:\n",
    "            selected_stocks[f'{days}_days'] = []\n",
    "            continue\n",
    "\n",
    "        # Scoring metrics\n",
    "        scoring = [\n",
    "            (sharpe, 1.5, False),\n",
    "            (sortino, 1.5, False),\n",
    "            (omega, 1.2, False),\n",
    "            ('EPS next Y', 1.0, False),\n",
    "            ('Profit M', 0.8, False),\n",
    "            ('PEG', 0.7, True),\n",
    "            ('Beta', 0.7, True),\n",
    "            ('Inst Own', 0.5, False),\n",
    "            ('Recom', 0.5, True)\n",
    "        ]\n",
    "\n",
    "        # Calculate scores\n",
    "        for metric, weight, invert in scoring:\n",
    "            z_vals = zscore(valid[metric], nan_policy='omit')\n",
    "            z_vals = np.nan_to_num(z_vals, nan=0.0)\n",
    "            if invert:\n",
    "                z_vals = -z_vals\n",
    "            valid[f'{metric}_score'] = z_vals * weight\n",
    "\n",
    "        # Total score\n",
    "        score_cols = [f'{metric}_score' for metric, _, _ in scoring]\n",
    "        valid['total_score'] = valid[score_cols].sum(axis=1)\n",
    "        \n",
    "        # # Select top 5\n",
    "        # top_5 = valid.nlargest(5, 'total_score')['Ticker'].tolist()\n",
    "        # print(f\"Selected top 5: {top_5}\")\n",
    "        # selected_stocks[f'{days}_days'] = top_5[:5]\n",
    "\n",
    "        # Select top 100\n",
    "        top_100 = valid.nlargest(100, 'total_score')['Ticker'].tolist()\n",
    "        print(f\"Selected top 100: {top_100}\")\n",
    "        selected_stocks[f'{days}_days'] = top_100[:100]\n",
    "\n",
    "\n",
    "    return selected_stocks\n",
    "\n",
    "def optimize_portfolio(selected_tickers, df_metrics, df_correlation):\n",
    "    \"\"\"Portfolio optimization with debug output\"\"\"\n",
    "    print(\"\\n=== Starting Portfolio Optimization ===\")\n",
    "    \n",
    "    # Handle Ticker index\n",
    "    if df_metrics.index.name == 'Ticker':\n",
    "        metrics = df_metrics\n",
    "        print(\"Ticker index already set in metrics\")\n",
    "    else:\n",
    "        metrics = df_metrics.set_index('Ticker')\n",
    "        print(\"Set Ticker index in metrics\")\n",
    "\n",
    "    # Common tickers handling\n",
    "    common = list(set(selected_tickers) \n",
    "                  & set(df_correlation.index) \n",
    "                  & set(metrics.index))\n",
    "    \n",
    "    print(f\"Common tickers: {common}\")\n",
    "    \n",
    "    if not common:\n",
    "        raise ValueError(\"No common tickers between selection and correlation matrix\")\n",
    "    \n",
    "    # Prepare data\n",
    "    df_corr = df_correlation.loc[common, common]\n",
    "    df_sub = metrics.loc[common]\n",
    "    \n",
    "    # Calculate covariance matrix\n",
    "    print(\"\\nCalculating covariance matrix...\")\n",
    "    volatilities = df_sub['Volatility M'] * np.sqrt(21)  # Monthly to annualized\n",
    "    cov_matrix = pd.DataFrame(\n",
    "        np.outer(volatilities, volatilities) * df_corr.values,\n",
    "        index=common,\n",
    "        columns=common\n",
    "    )\n",
    "    \n",
    "    # Calculate expected returns\n",
    "    print(\"Calculating expected returns...\")\n",
    "    df_sub['Expected Return'] = (\n",
    "        0.4 * df_sub['EPS next Y'] +\n",
    "        0.3 * df_sub['Profit M'] +\n",
    "        0.2 * df_sub['Sales Q/Q'] +\n",
    "        0.1 * (5 - df_sub['Recom'])  # Inverse since lower Recom is better\n",
    "    )\n",
    "    \n",
    "    # Portfolio optimization\n",
    "    print(\"Optimizing portfolio...\")\n",
    "    ef = EfficientFrontier(\n",
    "        expected_returns=df_sub['Expected Return'],\n",
    "        cov_matrix=cov_matrix,\n",
    "        weight_bounds=(0.02, 0.25)\n",
    "    )\n",
    "    ef.add_objective(objective_functions.L2_reg, gamma=0.1)\n",
    "    ef.max_sharpe()\n",
    "    \n",
    "    weights = ef.clean_weights()\n",
    "    print(\"\\n=== Optimization Results ===\")\n",
    "    print(\"Portfolio weights:\")\n",
    "    for ticker, weight in weights.items():\n",
    "        print(f\"{ticker}: {weight:.2%}\")\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def full_analysis_pipeline(df_metrics, df_correlation):\n",
    "    \"\"\"Complete pipeline with debug output\"\"\"\n",
    "    print(\"=== Starting Full Analysis Pipeline ===\")\n",
    "    \n",
    "    # Ensure metrics has Ticker index\n",
    "    if df_metrics.index.name != 'Ticker':\n",
    "        df_metrics = df_metrics.set_index('Ticker')\n",
    "        print(\"Set Ticker index in metrics DataFrame\")\n",
    "    \n",
    "    # Step 1: Stock selection\n",
    "    selected = select_outperforming_stocks(df_metrics)\n",
    "    all_tickers = list(set(\n",
    "        t for horizon in selected.values() \n",
    "        for t in horizon if isinstance(t, str)\n",
    "        ))\n",
    "    \n",
    "    print(f\"\\nFinal selected tickers: {all_tickers}\")\n",
    "    \n",
    "    # Step 2: Portfolio optimization\n",
    "    if not all_tickers:\n",
    "        raise ValueError(\"No stocks selected in initial filtering\")\n",
    "        \n",
    "    return optimize_portfolio(all_tickers, df_metrics, df_correlation)\n",
    "\n",
    "# Usage example:\n",
    "# df_metrics = pd.read_pickle(r'..\\data\\df_finviz_stocks_n_ratios.pkl')\n",
    "# df_correlation = pd.read_csv('correlation_matrix.csv', index_col=0)\n",
    "# portfolio = full_analysis_pipeline(df_metrics, df_correlation)\n",
    "\n",
    "df_metrics = pd.read_pickle('..\\data\\df_finviz_stocks_n_ratios.pkl')\n",
    "\n",
    "_df = pd.read_pickle('..\\data\\df_correlation_matrix.pkl')\n",
    "df_correlation = _df.loc[symbols, symbols]\n",
    "\n",
    "portfolio = full_analysis_pipeline(df_metrics, df_correlation)\n",
    "portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_metrics.index.name == 'Ticker':\n",
    "    metrics = df_metrics\n",
    "\n",
    "common = list(set(all_tickers) \n",
    "              & set(df_correlation.index) \n",
    "              & set(metrics.index))\n",
    "\n",
    "print(f'set(all_tickers) {len(all_tickers)}: {set(all_tickers)}')\n",
    "print(f'set(df_correlation.index) {len(df_correlation.index)}: {set(df_correlation.index)}')\n",
    "print(f'set(metrics.index) {len(metrics.index)}: {set(metrics.index)}')\n",
    "print(f\"Common tickers {len(common)}: {common}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = select_outperforming_stocks(df_metrics)\n",
    "all_tickers = list(set(\n",
    "    t for horizon in selected.values() \n",
    "    for t in horizon if isinstance(t, str)\n",
    "    ))\n",
    "\n",
    "print(f\"\\nFinal selected tickers {len(all_tickers)}: {all_tickers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.read_pickle('..\\data\\df_finviz_stocks_n_ratios.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.read_pickle('..\\data\\df_correlation_matrix.pkl')\n",
    "df_correlation = _df.loc[symbols, symbols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = full_analysis_pipeline(df_metrics, df_correlation)\n",
    "portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_outperforming_stocks(df):\n",
    "    \"\"\"Stock selection with full implementation\"\"\"\n",
    "    # Handle ticker position\n",
    "    if df.index.name == 'Ticker':\n",
    "        temp_df = df.reset_index()\n",
    "    else:\n",
    "        temp_df = df.copy()\n",
    "\n",
    "    # Validate required columns\n",
    "    required_cols = {\n",
    "        'Ticker', 'Sharpe 30d', 'Sortino 30d', 'Omega 30d',\n",
    "        'Sharpe 63d', 'Sortino 63d', 'Omega 63d', 'Sharpe 125d',\n",
    "        'Sortino 125d', 'Omega 125d', 'EPS next Y', 'Profit M',\n",
    "        'PEG', 'Beta', 'Inst Own', 'Recom'\n",
    "    }\n",
    "    missing = required_cols - set(temp_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    # Horizon configuration\n",
    "    horizons = {\n",
    "        15: '30d',\n",
    "        30: '30d', \n",
    "        60: '63d',\n",
    "        120: '125d'\n",
    "    }\n",
    "\n",
    "    selected_stocks = {}\n",
    "    \n",
    "    for days, suffix in horizons.items():\n",
    "        # Risk metrics\n",
    "        sharpe = f'Sharpe {suffix}'\n",
    "        sortino = f'Sortino {suffix}'\n",
    "        omega = f'Omega {suffix}'\n",
    "        \n",
    "        # Filter stocks\n",
    "        valid = temp_df[\n",
    "            (temp_df[sharpe] > 0) &\n",
    "            (temp_df[sortino] > 0) &\n",
    "            (temp_df[omega] > 1)\n",
    "        ].copy()\n",
    "        \n",
    "        if valid.empty:\n",
    "            selected_stocks[f'{days}_days'] = []\n",
    "            continue\n",
    "\n",
    "        # Scoring metrics\n",
    "        scoring = [\n",
    "            (sharpe, 1.5, False),\n",
    "            (sortino, 1.5, False),\n",
    "            (omega, 1.2, False),\n",
    "            ('EPS next Y', 1.0, False),\n",
    "            ('Profit M', 0.8, False),\n",
    "            ('PEG', 0.7, True),\n",
    "            ('Beta', 0.7, True),\n",
    "            ('Inst Own', 0.5, False),\n",
    "            ('Recom', 0.5, True)\n",
    "        ]\n",
    "\n",
    "        # Calculate scores\n",
    "        for metric, weight, invert in scoring:\n",
    "            z_vals = zscore(valid[metric], nan_policy='omit')\n",
    "            z_vals = np.nan_to_num(z_vals, nan=0.0)\n",
    "            if invert:\n",
    "                z_vals = -z_vals\n",
    "            valid[f'{metric}_score'] = z_vals * weight\n",
    "\n",
    "        # Total score\n",
    "        score_cols = [f'{metric}_score' for metric, _, _ in scoring]\n",
    "        valid['total_score'] = valid[score_cols].sum(axis=1)\n",
    "        \n",
    "        # Select top 5\n",
    "        top_5 = valid.nlargest(5, 'total_score')['Ticker'].tolist()\n",
    "        selected_stocks[f'{days}_days'] = top_5[:5]\n",
    "\n",
    "    return selected_stocks\n",
    "\n",
    "def optimize_portfolio(selected_tickers, df_metrics, df_correlation):\n",
    "    \"\"\"Portfolio optimization with index awareness\"\"\"\n",
    "    # Handle Ticker index in metrics\n",
    "    if df_metrics.index.name == 'Ticker':\n",
    "        metrics = df_metrics\n",
    "    else:\n",
    "        metrics = df_metrics.set_index('Ticker')\n",
    "    \n",
    "    # Common tickers handling\n",
    "    common = list(set(selected_tickers) \n",
    "                  & set(df_correlation.index) \n",
    "                  & set(metrics.index))\n",
    "    \n",
    "    # Prepare data\n",
    "    df_corr = df_correlation.loc[common, common]\n",
    "    df_sub = metrics.loc[common]  # Now using index directly\n",
    "    \n",
    "    # Rest of optimization code remains the same...\n",
    "\n",
    "    \"\"\"Portfolio optimization with full implementation\"\"\"\n",
    "    # Common tickers\n",
    "    common = list(set(selected_tickers) & set(df_correlation.index) & set(df_correlation.columns))\n",
    "    \n",
    "    # Prepare data\n",
    "    df_corr = df_correlation.loc[common, common]\n",
    "    df_sub = df_metrics.set_index('Ticker').loc[common]\n",
    "    \n",
    "    # Covariance matrix\n",
    "    volatilities = df_sub['Volatility M'] * np.sqrt(21)\n",
    "    cov_matrix = pd.DataFrame(\n",
    "        np.outer(volatilities, volatilities) * df_corr.values,\n",
    "        index=common,\n",
    "        columns=common\n",
    "    )\n",
    "    \n",
    "    # Expected returns\n",
    "    df_sub['Expected Return'] = (\n",
    "        0.4 * df_sub['EPS next Y'] +\n",
    "        0.3 * df_sub['Profit M'] +\n",
    "        0.2 * df_sub['Sales Q/Q'] +\n",
    "        0.1 * (5 - df_sub['Recom'])\n",
    "    )\n",
    "    \n",
    "    # Optimize\n",
    "    ef = EfficientFrontier(\n",
    "        df_sub['Expected Return'],\n",
    "        cov_matrix,\n",
    "        weight_bounds=(0.02, 0.25)\n",
    "    )\n",
    "    ef.add_objective(objective_functions.L2_reg, gamma=0.1)\n",
    "    ef.max_sharpe()\n",
    "    \n",
    "    return ef.clean_weights()\n",
    "\n",
    "def full_analysis_pipeline(df_metrics, df_correlation):\n",
    "    \"\"\"Complete pipeline with index safety\"\"\"\n",
    "    # Ensure metrics keeps Ticker index\n",
    "    if df_metrics.index.name != 'Ticker':\n",
    "        df_metrics = df_metrics.set_index('Ticker')\n",
    "    \n",
    "    # Run selection and optimization\n",
    "    selected = select_outperforming_stocks(df_metrics)\n",
    "    all_tickers = [t for sublist in selected.values() for t in sublist]\n",
    "    \n",
    "    return optimize_portfolio(all_tickers, df_metrics, df_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from pypfopt import EfficientFrontier, objective_functions\n",
    "\n",
    "def select_outperforming_stocks(df):\n",
    "    \"\"\"Stock selection with full implementation\"\"\"\n",
    "    # Handle ticker position\n",
    "    if df.index.name == 'Ticker':\n",
    "        temp_df = df.reset_index()\n",
    "    else:\n",
    "        temp_df = df.copy()\n",
    "\n",
    "    # Validate required columns\n",
    "    required_cols = {\n",
    "        'Ticker', 'Sharpe 30d', 'Sortino 30d', 'Omega 30d',\n",
    "        'Sharpe 63d', 'Sortino 63d', 'Omega 63d', 'Sharpe 125d',\n",
    "        'Sortino 125d', 'Omega 125d', 'EPS next Y', 'Profit M',\n",
    "        'PEG', 'Beta', 'Inst Own', 'Recom'\n",
    "    }\n",
    "    missing = required_cols - set(temp_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    # Horizon configuration\n",
    "    horizons = {\n",
    "        15: '30d',\n",
    "        30: '30d', \n",
    "        60: '63d',\n",
    "        120: '125d'\n",
    "    }\n",
    "\n",
    "    selected_stocks = {}\n",
    "    \n",
    "    for days, suffix in horizons.items():\n",
    "        # Risk metrics\n",
    "        sharpe = f'Sharpe {suffix}'\n",
    "        sortino = f'Sortino {suffix}'\n",
    "        omega = f'Omega {suffix}'\n",
    "        \n",
    "        # Filter stocks\n",
    "        valid = temp_df[\n",
    "            (temp_df[sharpe] > 0) &\n",
    "            (temp_df[sortino] > 0) &\n",
    "            (temp_df[omega] > 1)\n",
    "        ].copy()\n",
    "        \n",
    "        if valid.empty:\n",
    "            selected_stocks[f'{days}_days'] = []\n",
    "            continue\n",
    "\n",
    "        # Scoring metrics\n",
    "        scoring = [\n",
    "            (sharpe, 1.5, False),\n",
    "            (sortino, 1.5, False),\n",
    "            (omega, 1.2, False),\n",
    "            ('EPS next Y', 1.0, False),\n",
    "            ('Profit M', 0.8, False),\n",
    "            ('PEG', 0.7, True),\n",
    "            ('Beta', 0.7, True),\n",
    "            ('Inst Own', 0.5, False),\n",
    "            ('Recom', 0.5, True)\n",
    "        ]\n",
    "\n",
    "        # Calculate scores\n",
    "        for metric, weight, invert in scoring:\n",
    "            z_vals = zscore(valid[metric], nan_policy='omit')\n",
    "            z_vals = np.nan_to_num(z_vals, nan=0.0)\n",
    "            if invert:\n",
    "                z_vals = -z_vals\n",
    "            valid[f'{metric}_score'] = z_vals * weight\n",
    "\n",
    "        # Total score\n",
    "        score_cols = [f'{metric}_score' for metric, _, _ in scoring]\n",
    "        valid['total_score'] = valid[score_cols].sum(axis=1)\n",
    "        \n",
    "        # Select top 5\n",
    "        top_5 = valid.nlargest(5, 'total_score')['Ticker'].tolist()\n",
    "        selected_stocks[f'{days}_days'] = top_5[:5]\n",
    "\n",
    "    return selected_stocks\n",
    "\n",
    "def optimize_portfolio(selected_tickers, df_metrics, df_correlation):\n",
    "    \"\"\"Portfolio optimization with full implementation\"\"\"\n",
    "    # Common tickers\n",
    "    common = list(set(selected_tickers) & set(df_correlation.index) & set(df_correlation.columns))\n",
    "    \n",
    "    # Prepare data\n",
    "    df_corr = df_correlation.loc[common, common]\n",
    "    df_sub = df_metrics.set_index('Ticker').loc[common]\n",
    "    \n",
    "    # Covariance matrix\n",
    "    volatilities = df_sub['Volatility M'] * np.sqrt(21)\n",
    "    cov_matrix = pd.DataFrame(\n",
    "        np.outer(volatilities, volatilities) * df_corr.values,\n",
    "        index=common,\n",
    "        columns=common\n",
    "    )\n",
    "    \n",
    "    # Expected returns\n",
    "    df_sub['Expected Return'] = (\n",
    "        0.4 * df_sub['EPS next Y'] +\n",
    "        0.3 * df_sub['Profit M'] +\n",
    "        0.2 * df_sub['Sales Q/Q'] +\n",
    "        0.1 * (5 - df_sub['Recom'])\n",
    "    )\n",
    "    \n",
    "    # Optimize\n",
    "    ef = EfficientFrontier(\n",
    "        df_sub['Expected Return'],\n",
    "        cov_matrix,\n",
    "        weight_bounds=(0.02, 0.25)\n",
    "    )\n",
    "    ef.add_objective(objective_functions.L2_reg, gamma=0.1)\n",
    "    ef.max_sharpe()\n",
    "    \n",
    "    return ef.clean_weights()\n",
    "\n",
    "def full_analysis_pipeline(df_metrics, df_correlation):\n",
    "    \"\"\"Complete working pipeline\"\"\"\n",
    "    # Step 1: Stock selection\n",
    "    selected = select_outperforming_stocks(df_metrics)\n",
    "    all_tickers = list(set(\n",
    "        t for horizon in selected.values() \n",
    "        for t in horizon if isinstance(t, str)\n",
    "    ))\n",
    "    \n",
    "    # Step 2: Portfolio optimization\n",
    "    if not all_tickers:\n",
    "        raise ValueError(\"No stocks selected in initial filtering\")\n",
    "        \n",
    "    return optimize_portfolio(all_tickers, df_metrics, df_correlation)\n",
    "\n",
    "# Usage:\n",
    "# df_metrics = pd.read_pickle(r'..\\data\\df_finviz_stocks_n_ratios.pkl')\n",
    "# df_correlation = pd.read_csv('correlation_matrix.csv', index_col=0)\n",
    "# portfolio = full_analysis_pipeline(df_metrics, df_correlation)\n",
    "# print(portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def select_outperforming_stocks(df):\n",
    "    \"\"\"\n",
    "    Analyze stock metrics to select top 5 outperforming stocks with acceptable risk\n",
    "    across multiple time horizons. Handles Tickers both as columns and index.\n",
    "    \"\"\"\n",
    "    # Validate input and handle ticker position\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "    \n",
    "    # Create working copy and check ticker position\n",
    "    temp_df = df.copy()\n",
    "    if 'Ticker' not in temp_df.columns:\n",
    "        if temp_df.index.name == 'Ticker':\n",
    "            temp_df = temp_df.reset_index()\n",
    "        else:\n",
    "            raise ValueError(\"Ticker information not found in columns or index\")\n",
    "\n",
    "    # Check required columns\n",
    "    required_cols = {\n",
    "        'Ticker', 'Sharpe 30d', 'Sortino 30d', 'Omega 30d',\n",
    "        'Sharpe 63d', 'Sortino 63d', 'Omega 63d', 'Sharpe 125d',\n",
    "        'Sortino 125d', 'Omega 125d', 'EPS next Y', 'Profit M',\n",
    "        'PEG', 'Beta', 'Inst Own', 'Recom'\n",
    "    }\n",
    "    \n",
    "    missing = required_cols - set(temp_df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    # Horizon configuration\n",
    "    horizons = {\n",
    "        15: ('30d', 'short'),\n",
    "        30: ('30d', 'short'),\n",
    "        60: ('63d', 'medium'),\n",
    "        120: ('125d', 'long')\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for days, (suffix, _) in horizons.items():\n",
    "        sharpe = f'Sharpe {suffix}'\n",
    "        sortino = f'Sortino {suffix}'\n",
    "        omega = f'Omega {suffix}'\n",
    "        \n",
    "        # Filter stocks with positive risk-adjusted returns\n",
    "        valid_stocks = temp_df[\n",
    "            (temp_df[sharpe] > 0) &\n",
    "            (temp_df[sortino] > 0) &\n",
    "            (temp_df[omega] > 1)\n",
    "        ].copy()\n",
    "        \n",
    "        if valid_stocks.empty:\n",
    "            results[f'{days}_days'] = []\n",
    "            continue\n",
    "\n",
    "        # Create scoring system\n",
    "        scoring_metrics = [\n",
    "            (sharpe, 1.5, False),\n",
    "            (sortino, 1.5, False),\n",
    "            (omega, 1.2, False),\n",
    "            ('EPS next Y', 1.0, False),\n",
    "            ('Profit M', 0.8, False),\n",
    "            ('PEG', 0.7, True),\n",
    "            ('Beta', 0.7, True),\n",
    "            ('Inst Own', 0.5, False),\n",
    "            ('Recom', 0.5, True)\n",
    "        ]\n",
    "\n",
    "        # Calculate weighted z-scores\n",
    "        for metric, weight, invert in scoring_metrics:\n",
    "            z_values = zscore(valid_stocks[metric], nan_policy='omit')\n",
    "            z_values = np.nan_to_num(z_values, nan=0.0)\n",
    "            if invert:\n",
    "                z_values = -z_values\n",
    "            valid_stocks[f'{metric}_score'] = z_values * weight\n",
    "\n",
    "        # Calculate total score\n",
    "        score_cols = [f'{metric}_score' for metric, _, _ in scoring_metrics]\n",
    "        valid_stocks['total_score'] = valid_stocks[score_cols].sum(axis=1)\n",
    "        \n",
    "        # Select top 5\n",
    "        top_5 = valid_stocks.nlargest(5, 'total_score')['Ticker'].tolist()\n",
    "        results[f'{days}_days'] = top_5[:5]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = select_outperforming_stocks(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
