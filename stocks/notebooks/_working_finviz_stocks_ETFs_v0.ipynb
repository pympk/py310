{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = '.styled-table-new'\n",
    "\n",
    "columns_list = ['No.', 'Ticker', 'Company', 'Sector', 'Industry', 'Market Cap',\n",
    "       'Dividend', 'Perf Week', 'Perf Month', 'Perf Quart', 'Perf Half',\n",
    "       'Perf Year', 'Perf YTD', 'Beta', 'ATR', 'Volatility W', 'Volatility M',\n",
    "       'SMA20', 'SMA50', 'SMA200', '52W High', '52W Low', 'RSI', 'Volume',\n",
    "       'Price', 'Change', 'Single Category', 'Asset Type', 'AUM', 'Return% 1Y',\n",
    "       'Return% 3Y', 'Return% 5Y',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random  # For a bit of randomness in the sleep time\n",
    "import pandas as pd\n",
    "\n",
    "def download_yahoo_finance_table(url, selector):\n",
    "    \"\"\"\n",
    "    Downloads table data from a Yahoo Finance page with rate limiting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add a User-Agent header to mimic a browser\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}  # Example User-Agent\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table_body = soup.select_one(selector)\n",
    "\n",
    "        if table_body is None:\n",
    "            print(f\"Error: Table body not found using selector: {selector}\")\n",
    "            return None\n",
    "\n",
    "        rows = table_body.find_all('tr')\n",
    "        if not rows:\n",
    "            print(\"Error: No rows found in the table.\")\n",
    "            return None\n",
    "\n",
    "        # Extract headers from the first row (th elements)\n",
    "        headers_list = [th.text.strip() for th in rows[0].find_all('th')]\n",
    "\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            if row_data:  # Only append if the row has data\n",
    "                data.append(row_data)\n",
    "\n",
    "        if not data:\n",
    "            print(\"Error: No data found in the table rows.\")\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(data, columns=headers_list)\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during request: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 101, new_columns_str: 0,1,2,3,4,6,14,40,42,43,44,45,46,47,48,49,50,51,52,53,54,55,57,58,59,65,66,67,100,103,109,120,121,122\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "url_mktcap ='https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c='\n",
    "url_columns ='0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122'\n",
    "url_rows = ['&r=1', '&r=21', '&r=41', '&r=61', '&r=81', '&r=101', '&r=121', '&r=141', '&r=161', '&r=181', '&r=201', '&r=221', '&r=241', '&r=261', '&r=281', '&r=301', '&r=321', '&r=341', '&r=361', '&r=381', '&r=401', '&r=421', '&r=441', '&r=461', '&r=481', '&r=501', '&r=521', '&r=541', '&r=561', '&r=581', '&r=601', '&r=621', '&r=641', '&r=661', '&r=681', '&r=701', '&r=721', '&r=741', '&r=761', '&r=781', '&r=801', '&r=821', '&r=841', '&r=861', '&r=881', '&r=901', '&r=921', '&r=941', '&r=961', '&r=981']\n",
    "shuffled_url_rows = random.sample(url_rows, len(url_rows))  # Returns a new shuffled list\n",
    "\n",
    "def add_random_column(columns_str):\n",
    "    # Handle empty input to avoid conversion errors\n",
    "    columns = []\n",
    "    if columns_str:\n",
    "        columns = [int(x) for x in columns_str.split(',')]\n",
    "    \n",
    "    # Generate set of available numbers (0-130 not in columns)\n",
    "    available_nums = set(range(131)) - set(columns)\n",
    "    \n",
    "    if available_nums:\n",
    "        # Determine how many numbers to add (1-3, but not exceeding available count)\n",
    "        max_possible = len(available_nums)\n",
    "        max_k = min(3, max_possible)\n",
    "        k = random.randint(1, max_k)  # Randomly choose 1, 2, or 3 (or up to max possible)\n",
    "        \n",
    "        # Sample k unique numbers from available_nums\n",
    "        new_columns = random.sample(list(available_nums), k)\n",
    "        \n",
    "        # Add new numbers to the list and sort\n",
    "        columns.extend(new_columns)\n",
    "        columns.sort()\n",
    "        \n",
    "        # Convert back to string\n",
    "        return ','.join(map(str, columns))\n",
    "    else:\n",
    "        # Return original if no numbers available\n",
    "        return columns_str\n",
    "    \n",
    "random_columns = add_random_column(url_columns)\n",
    "print(f\"len: {len(random_columns)}, new_columns_str: {random_columns}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(urls): 50\n",
      "['https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,65,66,67,87,100,103,109,120,121,122&r=981', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,65,66,67,71,100,103,109,120,121,122&r=761', 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,65,66,67,100,103,104,109,110,120,121,122,130&r=801']\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "\n",
    "for _rows in shuffled_url_rows:\n",
    "    random_columns = add_random_column(url_columns)\n",
    "    url = url_mktcap + random_columns + _rows\n",
    "    urls.append(url)\n",
    "\n",
    "\n",
    "print(f'len(urls): {len(urls)}')\n",
    "print(urls[0:3])  # Print the length of the list of url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "urls_to_download = urls[0:3]  # Adjust the range as needed\n",
    "total_urls_to_download = len(urls_to_download)\n",
    "\n",
    "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
    "processed_count = 0\n",
    "\n",
    "\n",
    "for url in urls_to_download :\n",
    "    # Introduce a delay between requests (adjust as needed)\n",
    "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
    "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
    "    processed_count += 1\n",
    "    print(f\"Downloading {url}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_urls_to_download} urls\")\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    df_temp = download_yahoo_finance_table(url, selector)\n",
    "\n",
    "    if df_temp is not None:\n",
    "        df_temp_filtered = df_temp[columns_list]\n",
    "        df = pd.concat([df, df_temp_filtered])  # Append to the combined DataFrame\n",
    "    else:\n",
    "        print(f\"Failed to download data for {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_rows = ['&r=1', '&r=21', '&r=41', '&r=61', '&r=81', '&r=101', '&r=121', '&r=141', '&r=161', '&r=181', '&r=201', '&r=221', '&r=241', '&r=261', '&r=281', '&r=301', '&r=321', '&r=341', '&r=361', '&r=381', '&r=401', '&r=421', '&r=441', '&r=461', '&r=481', '&r=501', '&r=521', '&r=541', '&r=561', '&r=581', '&r=601', '&r=621', '&r=641', '&r=661', '&r=681', '&r=701', '&r=721', '&r=741', '&r=761', '&r=781', '&r=801', '&r=821', '&r=841', '&r=861', '&r=881', '&r=901', '&r=921', '&r=941', '&r=961', '&r=981']\n",
    "shuffled_url_rows = random.sample(url_rows, len(url_rows))  # Returns a new shuffled list\n",
    "print(f\"len: {len(shuffled_url_rows)}, url_rows: {shuffled_url_rows}\")\n",
    "print(f\"len: {len(shuffled_url_rows)}, urls: {shuffled_url_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequence from 0 to 981 with step size 20\n",
    "sequence = list(range(1, 1001, 20))\n",
    "\n",
    "# print(len(sequence), len(sequence)*20)\n",
    "# print(sequence)\n",
    "\n",
    "url_rows = [f\"&r={num}\" for num in sequence]\n",
    "print(url_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = url_mktcap_head + random_columns_str + url_rows[0]\n",
    "my_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = download_yahoo_finance_table(my_url, selector)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base ='https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_random_sequence(sequence_list):\n",
    "  # Make a copy of the original list to avoid modifying it\n",
    "  working_sequence = sequence_list.copy()\n",
    "  random_sequence = []\n",
    "  \n",
    "  # Continue until working_sequence is empty\n",
    "  while working_sequence:\n",
    "    # Select a random item from working_sequence\n",
    "    random_item = random.choice(working_sequence)\n",
    "    # Remove the selected item from working_sequence\n",
    "    working_sequence.remove(random_item)\n",
    "    # Add the selected item to random_sequence\n",
    "    random_sequence.append(random_item)\n",
    "  \n",
    "  return random_sequence\n",
    "\n",
    "# Create randomized sequence\n",
    "randomized_sequence = get_random_sequence(sequence)\n",
    "print(f\"Randomized sequence length: {len(randomized_sequence)}\")\n",
    "print(f\"Original sequence length: {len(sequence)}\")\n",
    "print(f'Randomized sequence: {randomized_sequence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of URLs by appending each number from sequence[0:2] to url_base\n",
    "urls_to_download = [url_base + str(num) for num in sequence[0:2]]\n",
    "urls_to_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_download_0 = 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=0,1,2,3,4,6,14,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=0'\n",
    "urls_to_download_1 = 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=50,1,2,3,4,6,14,42,43,44,45,46,47,48,49,0,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122,126&r=21'\n",
    "# urls_to_download_2 = 'https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&c=50,1,2,3,4,6,14,42,43,44,45,46,47,48,49,0,51,52,53,54,57,58,59,67,65,66,103,100,109,120,121,122&r=0,21'\n",
    "\n",
    "\n",
    "urls_to_download = [urls_to_download_0, urls_to_download_1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_0 = download_yahoo_finance_table(urls_to_download_0, selector)\n",
    "df_1 = download_yahoo_finance_table(urls_to_download_1, selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_0.info(), df_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# urls_to_download = urls[1]  # Adjust the range as needed\n",
    "total_urls_to_download = len(urls_to_download)\n",
    "\n",
    "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
    "processed_count = 0\n",
    "\n",
    "\n",
    "for url in urls_to_download :\n",
    "    # Introduce a delay between requests (adjust as needed)\n",
    "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
    "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
    "    processed_count += 1\n",
    "    print(f\"Downloading {url}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_urls_to_download} urls\")\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    df_temp = download_yahoo_finance_table(url, selector)\n",
    "\n",
    "    if df_temp is not None:\n",
    "        # df_temp.columns = col_names # Ensure the columns are what is expected\n",
    "\n",
    "        # df_temp.set_index('Date', inplace=True) # Set Date as Index\n",
    "        # # Create MultiIndex\n",
    "        # df_temp.index = pd.MultiIndex.from_product([[symbol], df_temp.index], names=['Symbol', 'Date'])\n",
    "\n",
    "        df = pd.concat([df, df_temp])  # Append to the combined DataFrame\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download data for {url}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = download_yahoo_finance_table(urls_to_download, selector)\n",
    "# df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = download_yahoo_finance_table(urls_to_download, selector)\n",
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp = download_yahoo_finance_table(urls_to_download, selector)\n",
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = download_yahoo_finance_table(urls_to_download, selector)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = download_yahoo_finance_table('https://finviz.com/screener.ashx?v=152&ft=4&o=-marketcap&r=21', selector)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# urls_to_download = urls[1]  # Adjust the range as needed\n",
    "total_urls_to_download = len(urls_to_download)\n",
    "\n",
    "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
    "processed_count = 0\n",
    "\n",
    "\n",
    "for url in urls_to_download :\n",
    "    # Introduce a delay between requests (adjust as needed)\n",
    "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
    "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
    "    processed_count += 1\n",
    "    print(f\"Downloading {url}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_urls_to_download} urls\")\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    df_temp = download_yahoo_finance_table(url, selector)\n",
    "\n",
    "    if df_temp is not None:\n",
    "        # df_temp.columns = col_names # Ensure the columns are what is expected\n",
    "\n",
    "        # df_temp.set_index('Date', inplace=True) # Set Date as Index\n",
    "        # # Create MultiIndex\n",
    "        # df_temp.index = pd.MultiIndex.from_product([[symbol], df_temp.index], names=['Symbol', 'Date'])\n",
    "\n",
    "        df = pd.concat([df, df_temp])  # Append to the combined DataFrame\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download data for {url}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# urls_to_download = urls[1]  # Adjust the range as needed\n",
    "total_urls_to_download = len(urls_to_download)\n",
    "\n",
    "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
    "processed_count = 0\n",
    "\n",
    "\n",
    "for url in urls_to_download :\n",
    "    # Introduce a delay between requests (adjust as needed)\n",
    "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
    "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
    "    processed_count += 1\n",
    "    print(f\"Downloading {url}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_urls_to_download} urls\")\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    df_temp = download_yahoo_finance_table(url, selector)\n",
    "\n",
    "    if df_temp is not None:\n",
    "        # df_temp.columns = col_names # Ensure the columns are what is expected\n",
    "\n",
    "        # df_temp.set_index('Date', inplace=True) # Set Date as Index\n",
    "        # # Create MultiIndex\n",
    "        # df_temp.index = pd.MultiIndex.from_product([[symbol], df_temp.index], names=['Symbol', 'Date'])\n",
    "\n",
    "        df = pd.concat([df, df_temp])  # Append to the combined DataFrame\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download data for {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-l-EoNiu1xa"
   },
   "source": [
    "**===== TURN ON POWERTOY AWAKE to KEEP CONNECTION ALIVE =====**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1741810441193,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "BWX6sLNsmsCr",
    "outputId": "c9e4409d-a736-4051-bff3-e8888fdeb452"
   },
   "outputs": [],
   "source": [
    "# symbols: The string (or sequence) to slice.\n",
    "# start_index: Optional. The starting index of the slice. If None, defaults to 0.\n",
    "# end_index: Optional. The ending index of the slice (exclusive). If None, defaults to the end of the string.\n",
    "# step_value: Optional. The step value for the slice. If None, defaults to 1.\n",
    "\n",
    "start_index = None\n",
    "\n",
    "end_index = None\n",
    "# end_index = 3\n",
    "\n",
    "step_value = None\n",
    "slice_obj = slice(start_index, end_index, step_value)  # Create a slice object\n",
    "\n",
    "print(f'slice of symbols: symbols[{slice_obj}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741810441213,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "5xU6_zZ_Lz4C"
   },
   "outputs": [],
   "source": [
    "dir_path = 'G:/My Drive/stocks/'  # Run in PC, Replace with your actual directory path\n",
    "dir_path = '/content/drive/MyDrive/stocks/'  # Run in Colab\n",
    "\n",
    "symbols_stocks_file = 'symbols_stocks.txt'\n",
    "symbols_ETFs_file = 'symbols_ETFs.txt'\n",
    "# symbols_stocks_ETFs_file = 'symbols_stocks_ETFs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1741810441236,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "JFoObQEnMgao"
   },
   "outputs": [],
   "source": [
    "# selector = \"#nimbus-app > section > section > section > article > div.container > div.table-container.yf-1jecxey > table > tbody\"\n",
    "selector = \"#nimbus-app > section > section > section > article > div.container > div.table-container.yf-1jecxey\"\n",
    "col_names = ['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1741810441240,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "CBBGEXx86d3u"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_stock_symbols(dir_path, symbols_stocks_file, symbols_ETFs_file):\n",
    "    \"\"\"\n",
    "    Reads stock and ETF symbols from text files in the specified directory and returns them in two separate lists.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): The directory path where the symbol files are located.\n",
    "        symbols_stocks_file (str): The name of the file containing stock symbols.\n",
    "        symbols_ETFs_file (str): The name of the file containing ETF symbols.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists: (stock_symbols, etf_symbols).  Returns ([], [])\n",
    "               if any error occurs during file reading.\n",
    "    \"\"\"\n",
    "\n",
    "    stock_symbols = []\n",
    "    etf_symbols = []\n",
    "\n",
    "    try:\n",
    "        # Read stock symbols\n",
    "        with open(os.path.join(dir_path, symbols_stocks_file), 'r') as f:\n",
    "            stock_symbols = [line.strip() for line in f]\n",
    "\n",
    "        # Read ETF symbols\n",
    "        with open(os.path.join(dir_path, symbols_ETFs_file), 'r') as f:\n",
    "            etf_symbols = [line.strip() for line in f]\n",
    "\n",
    "        return stock_symbols, etf_symbols\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: One or more files not found in directory: {dir_path}\")\n",
    "        return [], []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1421,
     "status": "ok",
     "timestamp": 1741810442663,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "Y0osnmZJ9cNp"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random  # For a bit of randomness in the sleep time\n",
    "\n",
    "def download_yahoo_finance_table(url, selector):\n",
    "    \"\"\"\n",
    "    Downloads table data from a Yahoo Finance page with rate limiting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add a User-Agent header to mimic a browser\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}  # Example User-Agent\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table_body = soup.select_one(selector)\n",
    "\n",
    "        if table_body is None:\n",
    "            print(f\"Error: Table body not found using selector: {selector}\")\n",
    "            return None\n",
    "\n",
    "        rows = table_body.find_all('tr')\n",
    "        if not rows:\n",
    "            print(\"Error: No rows found in the table.\")\n",
    "            return None\n",
    "\n",
    "        # Extract headers from the first row (th elements)\n",
    "        headers_list = [th.text.strip() for th in rows[0].find_all('th')]\n",
    "\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            row_data = [cell.text.strip() for cell in cells]\n",
    "            if row_data:  # Only append if the row has data\n",
    "                data.append(row_data)\n",
    "\n",
    "        if not data:\n",
    "            print(\"Error: No data found in the table rows.\")\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(data, columns=headers_list)\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during request: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1741810442669,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "b09-RblqEdrU"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "def get_current_pst_time():\n",
    "  \"\"\"\n",
    "  Returns the current time in Pacific Standard Time (PST).\n",
    "\n",
    "  Returns:\n",
    "    A string representing the current time in PST, formatted as\n",
    "    \"YYYY-MM-DD HH:MM:SS\".\n",
    "  \"\"\"\n",
    "\n",
    "  pst_timezone = pytz.timezone('America/Los_Angeles')  # Get the PST timezone\n",
    "  pst_now = datetime.datetime.now(pst_timezone)  # Get the current time in PST\n",
    "\n",
    "  return pst_now.strftime(\"%Y-%m-%d %H:%M:%S\")  # Format the time as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1319,
     "status": "ok",
     "timestamp": 1741810443987,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "JcZQy0VPfwlX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def convert_df_data_types(df):\n",
    "    \"\"\"\n",
    "    Cleans and converts a Pandas DataFrame with a MultiIndex to the specified data types.\n",
    "\n",
    "    Args:\n",
    "        df: The input Pandas DataFrame.  Assumes a MultiIndex with stock ticker (str) and date (str).\n",
    "            Assumes columns 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume' as objects.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame with the correct data types.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the second level of the MultiIndex to datetime\n",
    "    try:\n",
    "        df.index = pd.MultiIndex.from_tuples([(i[0], pd.to_datetime(i[1])) for i in df.index], names=df.index.names)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting MultiIndex to datetime: {e}\")\n",
    "        return df  # Or handle the error differently, e.g., raise it\n",
    "\n",
    "    # Convert columns to appropriate data types\n",
    "    columns_to_convert = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "    for col in columns_to_convert:\n",
    "        try:\n",
    "            # Remove commas *before* attempting conversion. CRITICAL.\n",
    "            df[col] = df[col].str.replace(',', '', regex=False)  # Remove commas first\n",
    "            df[col] = df[col].astype(float)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error converting column '{col}' to float: {e}\")\n",
    "            return df #skip this column and return the original df\n",
    "\n",
    "    try:\n",
    "        # Handle '-' values in 'Volume' BEFORE removing commas\n",
    "        df['Volume'] = df['Volume'].replace('-', np.nan)\n",
    "        df['Volume'] = df['Volume'].str.replace(',', '', regex=False).astype(float).astype('Int64') # Use Int64 to store NaN\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting column 'Volume' to int64: {e}\")\n",
    "        return df\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1741810444007,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "_BUoxDzZhnFg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def adjust_prices(df):\n",
    "    \"\"\"\n",
    "    Adjusts Open, High, Low, and Close prices using Adj Close to account for splits and dividends.\n",
    "\n",
    "    Args:\n",
    "        df: Pandas DataFrame with 'Open', 'High', 'Low', 'Close', and 'Adj Close' columns.\n",
    "            Assumes MultiIndex with stock ticker and datetime.\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with adjusted 'Open', 'High', and 'Low' prices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the adjustment ratio\n",
    "    df['adjustment_ratio'] = df['Adj Close'] / df['Close']\n",
    "\n",
    "    # Adjust Open, High, and Low prices\n",
    "    df['Adj Open'] = df['Open'] * df['adjustment_ratio']\n",
    "    df['Adj High'] = df['High'] * df['adjustment_ratio']\n",
    "    df['Adj Low'] = df['Low'] * df['adjustment_ratio']\n",
    "\n",
    "\n",
    "    # Optionally, drop the adjustment_ratio column if you don't need it\n",
    "    df = df.drop('adjustment_ratio', axis=1)  # axis=1 to drop the column\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example Usage (assuming 'df' is your cleaned DataFrame)\n",
    "# df_adjusted = adjust_prices(df.copy())  # Create a copy\n",
    "# print(df_adjusted.head())\n",
    "# print(df_adjusted.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1741810444841,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "fpOAu-6QsbsS",
    "outputId": "dde2b197-2698-4ef6-938b-57ff0b5f1929"
   },
   "outputs": [],
   "source": [
    "stocks, etfs = read_stock_symbols(dir_path, symbols_stocks_file, symbols_ETFs_file)\n",
    "\n",
    "if stocks or etfs:  # Check if either list has data, indicating successful read\n",
    "    print(f\"Stock Symbols (len = {len(stocks)}):\")\n",
    "    print(stocks)\n",
    "    print(f\"ETF Symbols (len = {len(etfs)}):\")\n",
    "    print(etfs)\n",
    "else:\n",
    "    print(\"Failed to read stock symbols. Check the directory and file names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1741810444925,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "2uHousBDsw1y",
    "outputId": "73f39fc5-b105-4bf4-e7e3-f31a7df124f1"
   },
   "outputs": [],
   "source": [
    "symbols = stocks + etfs\n",
    "print(f\"symbols (len = {len(symbols)}):\")\n",
    "print(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1741810444935,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "xuNqDb6dldkh",
    "outputId": "06915956-cad0-45dc-df3f-89a71825131f"
   },
   "outputs": [],
   "source": [
    "symbols_to_download = symbols[slice_obj]\n",
    "\n",
    "# symbols_to_download = slice_string(symbols, symbol_start, symbol_end, symbol_step)  # Adjust the slice as needed\n",
    "total_symbols_to_download = len(symbols_to_download)\n",
    "processed_count = 0\n",
    "\n",
    "print(f'symbols_to_download: symbols[{slice_obj}]')\n",
    "print(f'total_symbols_to_download: {total_symbols_to_download}')\n",
    "print(f'processed_count: {processed_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1741810445014,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "He4Rcsb5FLlf",
    "outputId": "422a7b36-0d01-4ae5-f87f-043fb7375e1a"
   },
   "outputs": [],
   "source": [
    "current_pst_time = get_current_pst_time()\n",
    "print(f\"Start OHLCV download at PST time: {current_pst_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11021114,
     "status": "ok",
     "timestamp": 1741821466135,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "NiiTtmZQsuR8",
    "outputId": "1b132eeb-243e-458d-9317-6c5d4d6abdf2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()  # Initialized an empty DataFrame\n",
    "\n",
    "for symbol in symbols_to_download:\n",
    "    url = f\"https://finance.yahoo.com/quote/{symbol}/history/\"\n",
    "    # Introduce a delay between requests (adjust as needed)\n",
    "    delay_seconds = random.uniform(2, 4.5)  # Sleep between 2 and 5 seconds\n",
    "    # print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds...\")\n",
    "    processed_count += 1\n",
    "    print(f\"Downloading {symbol}. Sleeping for {delay_seconds:.2f} seconds.  Processed {processed_count} / {total_symbols_to_download} symbols.\")\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    df_temp = download_yahoo_finance_table(url, selector)\n",
    "\n",
    "    if df_temp is not None:\n",
    "        df_temp.columns = col_names # Ensure the columns are what is expected\n",
    "\n",
    "        df_temp.set_index('Date', inplace=True) # Set Date as Index\n",
    "        # Create MultiIndex\n",
    "        df_temp.index = pd.MultiIndex.from_product([[symbol], df_temp.index], names=['Symbol', 'Date'])\n",
    "\n",
    "        df = pd.concat([df, df_temp])  # Append to the combined DataFrame\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to download data for {symbol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1741821466138,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "y5H2nS-SwcHt",
    "outputId": "7ce8240b-7cc1-401c-ee4d-78be198ce169"
   },
   "outputs": [],
   "source": [
    "current_pst_time = get_current_pst_time()\n",
    "print(f\"End OHLCV download at PST time: {current_pst_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1741821466149,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "pjgsQVdW_VAK",
    "outputId": "16e5b7ce-6ad1-4309-fb27-277250d6fa2b"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1741821467007,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "zDHlYAP8txlP",
    "outputId": "22789f49-4906-4025-9809-d67f950e8a95"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1741821467018,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "IbN2qjZfspQb",
    "outputId": "79277ba4-3dd1-4bae-d797-f89f47d3f805"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "pst = pytz.timezone('America/Los_Angeles')  # or 'US/Pacific'\n",
    "current_date_pst = datetime.datetime.now(pst).strftime('%Y-%m-%d')\n",
    "\n",
    "df_OHLCV_filename = f\"df_OHLCV_{current_date_pst}.pkl\"\n",
    "\n",
    "print(f\"df_OHLCV_filename: {df_OHLCV_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1293,
     "status": "ok",
     "timestamp": 1741821468314,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "_qVLTYVtunus",
    "outputId": "2bb3d9d6-6100-4d2b-de19-0e727c66e59b"
   },
   "outputs": [],
   "source": [
    "# Drop rows with any NaN values\n",
    "df_dropna = df.dropna()\n",
    "df_dropna.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 299455,
     "status": "ok",
     "timestamp": 1741821767768,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "znWY5QHxaDVR",
    "outputId": "f6d24f57-f0b6-4be1-f292-0df94f6ad83d"
   },
   "outputs": [],
   "source": [
    "df_converted = convert_df_data_types(df_dropna.copy())  # Create a copy to avoid modifying the original\n",
    "df_converted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1741821767915,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "2TAxKAEFhyQY",
    "outputId": "5d8440e7-9ef3-406b-af5b-90c9c7381d91"
   },
   "outputs": [],
   "source": [
    "df_adjusted = adjust_prices(df_converted.copy())  # Create a copy\n",
    "df_adjusted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1741821768001,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "r0WszJVfasuN",
    "outputId": "22854bf8-04da-405d-a9e9-97c18e18f16b"
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame to a pickle file\n",
    "df_adjusted.to_pickle(df_OHLCV_filename)  # Saves to the Colab's runtime environment\n",
    "\n",
    "print(f\"Dropped NaN, converted data types, adjusted OHLC and saved DataFrame saved as {df_OHLCV_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1741821768040,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "60RjbysEIFp8",
    "outputId": "6360c001-c0f8-4fce-b795-14a9efe67d0d"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the pickle file\n",
    "files.download(df_OHLCV_filename)\n",
    "print(f\"Downloded {df_OHLCV_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1741821768173,
     "user": {
      "displayName": "ping yee",
      "userId": "17916777163667289249"
     },
     "user_tz": 420
    },
    "id": "cWZKuITvTEec",
    "outputId": "41212f2d-4726-4ee9-da47-0e21b137a803"
   },
   "outputs": [],
   "source": [
    "df_adjusted"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP0Xbj8MojxCBwCH1wY3vgo",
   "mount_file_id": "1kPgpF6IeYD0Y-AVWLPiZ92O5i60rq7nT",
   "provenance": [
    {
     "file_id": "1IwwL6zZA9L74r4-OPTkHxJhLYSyUzc7V",
     "timestamp": 1741059324768
    },
    {
     "file_id": "1Kysq6BVvqd3O84m0gdT3BQm0jVwlp4XD",
     "timestamp": 1740622053247
    },
    {
     "file_id": "1XL4-86ZLWu8UIMKO6GL97YMbIdSslX5K",
     "timestamp": 1740587177316
    },
    {
     "file_id": "1KXs8MumJ78xO9mcgU8bnQwtev1ZYwIGm",
     "timestamp": 1740372106860
    },
    {
     "file_id": "19kXxHAiFbW12PG4kbS8SPisFq7mbgVQh",
     "timestamp": 1740371261418
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
