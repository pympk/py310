{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed26a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from py3810.myUtils import pickle_dump, pickle_load\n",
    "\n",
    "# Set the path to the directory containing the Excel file\n",
    "path_lumen_dump = \"../langchain/docs/lumen/\"\n",
    "path_lumen_docs = path_lumen_dump + \"docs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc6df54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.lumenoptometric.com/wp-content/uploads/2020/05/Intro_ScleralLenses.pdf',\n",
       " 'https://www.lumenoptometric.com/wp-content/uploads/2020/07/Lumen-HPA300-NP-Template.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lumen_urls_pdf = pickle_load(filename_pickle='lumen_urls_pdf', path_pickle_dump=path_lumen_dump)\n",
    "lumen_urls_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca31ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:    \n",
      "  This is a string  \n",
      "  with   multiple \n",
      " \n",
      " \n",
      "newlines.  \n",
      "=========\n",
      "text_cleaned: This is a string with multiple newlines.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_newlines(text):\n",
    "  # r'\\n|\\s{2,}' finds both newlines (\\n) and multiple whitespaces (\\s{2,}) \n",
    "  # and replace them with \" \", .strip() strips leading and trailing spaces \n",
    "  return re.sub(r'\\n|\\s{2,}', ' ', text).strip()\n",
    "\n",
    "text = \"   \\n  This is a string  \\n  with   multiple \\n \\n \\nnewlines.  \"\n",
    "text_cleaned = remove_newlines(text)\n",
    "print(f'text: {text}')\n",
    "print('=========')\n",
    "print(f'text_cleaned: {text_cleaned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97edc043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain document text: INTRODUCTION TO SCLERAL LENSESCLEAR & COMFORTABLE VISION WITHOUT COMPROMISE...\n",
      "Langchain document text: EXCEPTIONALLY CLEAR, STABLE, AND COMFORTABLE vision is no longer out of reach. The future is here an...\n"
     ]
    }
   ],
   "source": [
    "import langchain  # Assuming langchain is installed\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def convert_pdfs_to_langchain(pdf_urls):\n",
    "  \"\"\"\n",
    "  This function converts a list of PDF URLs to Langchain document objects\n",
    "  using PyPDFLoader for efficient processing.\n",
    "\n",
    "  Args:\n",
    "      pdf_urls: A list of URLs pointing to PDF files.\n",
    "\n",
    "  Returns:\n",
    "      A list of Langchain TextDocument objects.\n",
    "  \"\"\"\n",
    "  langchain_docs = []\n",
    "  for url in pdf_urls:\n",
    "    try:\n",
    "      # Use PyPDFLoader to read the PDF content locally (avoiding download)\n",
    "      loader = PyPDFLoader(url)\n",
    "      docs = loader.load()\n",
    "      for doc in docs:\n",
    "        # append only if page_content has text\n",
    "        if doc.page_content != \"\":\n",
    "          doc.page_content = remove_newlines(doc.page_content)  \n",
    "          langchain_docs.append(doc)\n",
    "\n",
    "        # langchain_docs.append(doc)\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing PDF from {url}: {e}\")\n",
    "  return langchain_docs\n",
    "\n",
    "# Example usage (same as before)\n",
    "pdf_urls = \\\n",
    "  ['https://www.lumenoptometric.com/wp-content/uploads/2020/05/Intro_ScleralLenses.pdf',\n",
    "   'https://www.lumenoptometric.com/wp-content/uploads/2020/07/Lumen-HPA300-NP-Template.pdf']\n",
    "langchain_documents = convert_pdfs_to_langchain(pdf_urls)\n",
    "\n",
    "# You can now use the Langchain documents for further processing\n",
    "for doc in langchain_documents:\n",
    "  print(f\"Langchain document text: {doc.page_content[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b18fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_pdfs = convert_pdfs_to_langchain(lumen_urls_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff7e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump(file_to_pickle=docs_pdfs, filename_pickle='lumen_docs_pdfs', path_pickle_dump=path_lumen_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
