{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References Langchain\n",
    "https://python.langchain.com/v0.1/docs/use_cases/question_answering/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References Chroma db  \n",
    "https://docs.trychroma.com/guides  \n",
    "https://github.com/neo-con/chromadb-tutorial  \n",
    "https://python.langchain.com/v0.1/docs/integrations/vectorstores/chroma/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from py3810.myUtils import pickle_dump, pickle_load\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv('.env\\my_api_key.env')) # read local .env file\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "os.environ[\"ToMarkDown_API_KEY\"]\n",
    "os.environ[\"SECRET_KEY\"]\n",
    "print(f\"SECRET_KEY = {os.environ['SECRET_KEY']}\")\n",
    "\n",
    "# Set the path to the directory containing the Excel file\n",
    "path_lumen_dump = \"../langchain/docs/lumen/\"\n",
    "path_lumen_docs = path_lumen_dump + \"docs/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, width=80):\n",
    "  \"\"\"\n",
    "  Prints a long string to the console, wrapped to fit within a specified width.\n",
    "\n",
    "  Args:\n",
    "      text: The long string to be wrapped.\n",
    "      width: The desired width for each line (default: 80 columns).\n",
    "  \"\"\"\n",
    "  wrapped_text = textwrap.wrap(text, width=width)\n",
    "  for line in wrapped_text:\n",
    "    print(line)\n",
    "\n",
    "# Example usage\n",
    "long_string = \"This is a very long string that needs to be wrapped to fit within 80 columns. It can contain spaces, punctuation, and even newlines.\"\n",
    "print_wrapped(long_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \".chatbot/chroma_openai_ef/\"\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "collection_name = 'lumen_docs_combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = \"What is lumen optometric's address?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only run cell below to add new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# load data\n",
    "doc_0 = pickle_load(filename_pickle='lumen_docs_website', path_pickle_dump=path_lumen_docs)\n",
    "doc_1 = pickle_load(filename_pickle='lumen_docs_youtube', path_pickle_dump=path_lumen_docs)\n",
    "doc_2 = pickle_load(filename_pickle='lumen_docs_videos', path_pickle_dump=path_lumen_docs)\n",
    "doc_3 = pickle_load(filename_pickle='lumen_docs_pdfs', path_pickle_dump=path_lumen_docs)\n",
    "\n",
    "docs = doc_0 + doc_1 + doc_2 + doc_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'len(splits): {len(splits)}')\n",
    "print(f'len(docs): {len(docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "  page_content = doc.page_content\n",
    "  metadata = doc.metadata\n",
    "  print(f'{i},  len(page_content): {len(page_content)}, meta_keys: {metadata.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(splits[0:4]):\n",
    "  page_content = doc.page_content\n",
    "  metadata = doc.metadata\n",
    "  print(f'{i},  len(page_content): {len(page_content)}, meta_keys: {metadata.keys()}')\n",
    "  for key, value in metadata.items():\n",
    "    print(f'{key}: {value}')\n",
    "  print('')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs[2]\n",
    "page_content = doc.page_content\n",
    "print(f'len(page_content): {len(page_content)}')\n",
    "print_wrapped(doc.page_content[0:200])\n",
    "print('')\n",
    "metadata = doc.metadata\n",
    "for key, value in doc.metadata.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = []\n",
    "\n",
    "for i, doc in enumerate(docs[0:2]):\n",
    "  my_row =[]\n",
    "  doc_index = i\n",
    "  page_content = doc.page_content\n",
    "  page_len = len(page_content)\n",
    "\n",
    "  metadata_dic = doc.metadata\n",
    "\n",
    "  try:\n",
    "    source = metadata_dic['source']\n",
    "  except KeyError:\n",
    "    source = None \n",
    "\n",
    "  try:\n",
    "    title = metadata_dic['title']\n",
    "  except KeyError:\n",
    "    title = None \n",
    "\n",
    "  try:\n",
    "    description = metadata_dic['description']\n",
    "  except KeyError:\n",
    "    description = None\n",
    "\n",
    "  print(f'doc_index: {doc_index}')\n",
    "  print(f'page_len: {page_len}')\n",
    "  print(f'page_content[0:50]: {page_content[0:50]}')  \n",
    "  print(f'source: {source}')  \n",
    "  print(f'title: {title}')\n",
    "  print(f'description: {description}\\n')\n",
    "  my_row.append(doc_index)\n",
    "  my_row.append(page_len)\n",
    "  my_row.append(page_content[0:10])\n",
    "  my_row.append(source)\n",
    "  my_row.append(description)\n",
    "  print(f'my_row: {my_row}')\n",
    "  my_data.append(my_row)\n",
    "\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(docs[0:2]):\n",
    "  # doc_index = i\n",
    "  # page_content = doc.page_content\n",
    "  # page_len = len(page_content)\n",
    "  # metadata_dic = doc.metadata\n",
    "  # source = metadata_dic['source']\n",
    "  # title = metadata_dic['title']\n",
    "  # description = metadata_dic['description']\n",
    "\n",
    "\n",
    "  print(f'docs[{i}], len(page_content): {len(page_content)}')\n",
    "  # print_wrapped(doc.page_content)\n",
    "  # print('')\n",
    "  metadata = doc.metadata\n",
    "  for key, value in doc.metadata.items():\n",
    "    print(f'{key}: {value}')\n",
    "  print(f'{\"=\"*10}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.docstore.document import Document\n",
    "\n",
    "# lumen_address_phone_hours = \\\n",
    "#   \"Lumen Optometric address is located at 14 West Sierra Madre Blvd, Sierra Madre, CA 91024. \\\n",
    "#    Lumen Optometric office is located at 14 West Sierra Madre Blvd, Sierra Madre, CA 91024. \\\n",
    "#    Lumen Optometric location is 14 West Sierra Madre Blvd, Sierra Madre, CA 91024. \\\n",
    "#    Lumen Optometric phone number is (626) 921-0199. \\\n",
    "#    Lumen Optometric office hours are Tuesday, Wednesday, Friday, and Saturday from 9:45 am to 5:30 pm, \\\n",
    "#    and Thursday from 9:45 am to 1:30 pm.\"\n",
    "\n",
    "# doc_lumen_address_phone_hours =  [Document(\n",
    "#   page_content=lumen_address_phone_hours,\n",
    "#   metadata={\"description\": \"address, office location, phone number, office hours\"}\n",
    "#   )]\n",
    "\n",
    "# # load data\n",
    "# doc_0 = pickle_load(filename_pickle='lumen_docs_website', path_pickle_dump=path_lumen_docs)\n",
    "# doc_1 = pickle_load(filename_pickle='lumen_docs_pdfs', path_pickle_dump=path_lumen_docs)\n",
    "# doc_2 = pickle_load(filename_pickle='lumen_docs_videos', path_pickle_dump=path_lumen_docs)\n",
    "# doc_3 = pickle_load(filename_pickle='lumen_docs_youtube', path_pickle_dump=path_lumen_docs)\n",
    "# docs = doc_lumen_address_phone_hours + doc_0 + doc_1 + doc_2 + doc_3\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# # save to disk\n",
    "# db0 = Chroma.from_documents(\n",
    "#   documents=splits,\n",
    "#   embedding=embedding_function,\n",
    "#   collection_name=collection_name,\n",
    "#   persist_directory=persist_directory\n",
    "#   )\n",
    "\n",
    "# db0_ans = db0.similarity_search(my_query)\n",
    "# # print(docs[0].page_content)\n",
    "# print(f'db0_ans:{db0_ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load from disk\n",
    "vectorstore = Chroma(\n",
    "  embedding_function=embedding_function,\n",
    "  collection_name=collection_name,\n",
    "  persist_directory=persist_directory\n",
    "  )\n",
    "ans = vectorstore.similarity_search(my_query)\n",
    "print(f'ans:{ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "  # \"14 West Sierra Madre Boulevard\",\n",
    "  \"What is lumen optometric's phone number?\",\n",
    "  \"What is lumen optometric's address?\",\n",
    "  \"What is lumen optometric's location?\",\n",
    "  \"do you take vision insurance\",\n",
    "  \"what type of insurance do you take\",\n",
    "  \"what are the names of the insurance that you take\",\n",
    "  \"What is Ortho-k\",\n",
    "  \"What does research say about Ortho-k\",\n",
    "  \"What equipment do they have?\",\n",
    "  \"What equipment do you use for othro-k?\",\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for query in queries[0:2]:\n",
    "for query in queries:\n",
    "  print(f'query: {query}')\n",
    "  print_wrapped(f'answr: {rag_chain.invoke(query)}')\n",
    "  print('')\n",
    "  print_wrapped(f'relevant docs: {retriever.get_relevant_documents(query)}')\n",
    "  print(f'{\"=\"*5}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
