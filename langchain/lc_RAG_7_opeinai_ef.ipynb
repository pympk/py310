{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References Langchain\n",
    "https://python.langchain.com/v0.1/docs/use_cases/question_answering/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References Chroma db  \n",
    "https://docs.trychroma.com/guides  \n",
    "https://github.com/neo-con/chromadb-tutorial  \n",
    "https://python.langchain.com/v0.1/docs/integrations/vectorstores/chroma/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from py3810.myUtils import pickle_dump, pickle_load\n",
    "path_lumen_docs = '..\\langchain\\docs\\lumen\\\\docs\\\\'\n",
    "path_chatbot = '..\\langchain\\chatbot\\\\'\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv('.env\\my_api_key.env')) # read local .env file\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]\n",
    "os.environ[\"SECRET_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, width=80):\n",
    "  \"\"\"\n",
    "  Prints a long string to the console, wrapped to fit within a specified width.\n",
    "\n",
    "  Args:\n",
    "      text: The long string to be wrapped.\n",
    "      width: The desired width for each line (default: 80 columns).\n",
    "  \"\"\"\n",
    "  wrapped_text = textwrap.wrap(text, width=width)\n",
    "  for line in wrapped_text:\n",
    "    print(line)\n",
    "\n",
    "# Example usage\n",
    "long_string = \"This is a very long string that needs to be wrapped to fit within 80 columns. It can contain spaces, punctuation, and even newlines.\"\n",
    "print_wrapped(long_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = path_chatbot + \"./chroma_openai_ef\"\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "collection_name = 'lumen_docs_combined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only run cell below to add new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data\n",
    "# docs = pickle_load(filename_pickle='lumen_docs_combined', path_pickle_dump=path_chatbot)\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# # save to disk\n",
    "# db0 = Chroma.from_documents(\n",
    "#   documents=splits,\n",
    "#   embedding=embedding_function,\n",
    "#   collection_name=collection_name,\n",
    "#   persist_directory=persist_directory\n",
    "#   )\n",
    "# db0_ans = db0.similarity_search(query)\n",
    "# # print(docs[0].page_content)\n",
    "# print(f'db0_ans:{db0_ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = 'where is lumen optometric'\n",
    "\n",
    "# load from disk\n",
    "vectorstore = Chroma(\n",
    "  embedding_function=embedding_function,\n",
    "  collection_name=collection_name,\n",
    "  persist_directory=persist_directory\n",
    "  )\n",
    "ans = vectorstore.similarity_search(my_query)\n",
    "print(f'ans:{ans}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "  \"What is lumen optometric's phone number?\",\n",
    "  \"What is lumen optometric's address?\",\n",
    "  \"What is lumen optometric's location?\",\n",
    "  \"do you take vision insurance\",\n",
    "  \"what type of insurance do you take\",\n",
    "  \"what are the names of the insurance that you take\",\n",
    "  \"What is Ortho-k\",\n",
    "  \"What does research say about Ortho-k\",\n",
    "  \"What equipment do they have?\",\n",
    "  \"What equipment do you use for othro-k?\",\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for query in queries[0:2]:\n",
    "for query in queries[0:3]:\n",
    "  print(f'query: {query}')\n",
    "  print_wrapped(f'answr: {rag_chain.invoke(query)}')\n",
    "  print('')\n",
    "  print_wrapped(f'relevant docs: {retriever.get_relevant_documents(query)}')\n",
    "  print(f'{\"=\"*5}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
