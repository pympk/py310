{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2065797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain\\Keeping Aidans Eyes Healthy With Myopia Management.mp4\n",
    "langchain\\Keeping Aidans Eyes Healthy With Myopia Management.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf58e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_audio = '..\\langchain\\Keeping Aidans Eyes Healthy With Myopia Management.mp4'\n",
    "path_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# result = model.transcribe(path_audio, language=\"fr\")  # Transcribe in French\n",
    "result = model.transcribe(path_audio, language=\"en\")  # Transcribe in French\n",
    "\n",
    "print(result[\"text\"])\n",
    "\n",
    "# Generate subtitles\n",
    "print(result[\"segments\"])  # List of segments with start, end, and text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "def whisper_parser(audio_file):\n",
    "  \"\"\"Parses an audio file using the Whisper model.\n",
    "\n",
    "  Args:\n",
    "    audio_file: Path to the audio file.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing the transcription results.\n",
    "  \"\"\"\n",
    "\n",
    "  model = whisper.load_model(\"base\")  # Replace \"base\" with desired model size\n",
    "  result = model.transcribe(audio_file)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8546f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whisper_parser(audio_file):\n",
    "  \"\"\"Parses an audio file using the Whisper model and returns a Document object.\n",
    "\n",
    "  Args:\n",
    "    audio_file: Path to the audio file.\n",
    "\n",
    "  Returns:\n",
    "    A Document object containing the transcription results.\n",
    "  \"\"\"\n",
    "\n",
    "  model = whisper.load_model(\"base\")  # Replace \"base\" with desired model size\n",
    "  result = model.transcribe(audio_file)\n",
    "  # Create a Document object with the text and other relevant details (optional)\n",
    "  document = Document(text=result[\"text\"])\n",
    "  return document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f949e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "# from langchain.document import Document\n",
    "# from langchain.document import Document\n",
    "\n",
    "def whisper_parser(audio_file):\n",
    "  \"\"\"Parses an audio file using the Whisper model (lazy parsing implementation optional).\n",
    "\n",
    "  Args:\n",
    "    audio_file: Path to the audio file.\n",
    "\n",
    "  Yields:\n",
    "    A Document object containing the transcription results (optional).\n",
    "  \"\"\"\n",
    "\n",
    "  model = whisper.load_model(\"base\")  # Replace \"base\" with desired model size\n",
    "  # Implement lazy parsing logic here (e.g., using generators)\n",
    "  # ...\n",
    "  yield Document(text=result[\"text\"])  # Example yield statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378c9412",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'GenericLoader' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m loader \u001b[38;5;241m=\u001b[39m GenericLoader(YoutubeAudioLoader(urls, save_dir), whisper_parser)\n\u001b[0;32m     29\u001b[0m docs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m loader:  \u001b[38;5;66;03m# Iterate over the loader to get documents\u001b[39;00m\n\u001b[0;32m     31\u001b[0m   \u001b[38;5;66;03m# Process each document object here\u001b[39;00m\n\u001b[0;32m     32\u001b[0m   doc \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload() \n\u001b[0;32m     33\u001b[0m   docs\u001b[38;5;241m.\u001b[39mappend(doc)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'GenericLoader' object is not iterable"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import os\n",
    "\n",
    "def convert_to_mp3(input_file, output_file):\n",
    "    \"\"\"Converts an audio file to MP3 format.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input audio file.\n",
    "        output_file (str): Path to the output MP3 file.\n",
    "    \"\"\"\n",
    "    sound = AudioSegment.from_file(input_file)\n",
    "    sound.export(output_file, format=\"mp3\")\n",
    "\n",
    "# List of YouTube URLs\n",
    "urls = [\"https://www.youtube.com/watch?v=9eIMWmRG12w\", \"https://www.youtube.com/watch?v=Pg4w-rwTCXE\"]\n",
    "\n",
    "# Directory to save audio files\n",
    "save_dir = \"~/Downloads/YouTube\"\n",
    "\n",
    "# Create a loader instance\n",
    "# loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())\n",
    "# loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), whisper_parser)\n",
    "# loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), whisper_parser)\n",
    "loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), whisper_parser)\n",
    "docs = []\n",
    "for doc in loader:  # Iterate over the loader to get documents\n",
    "  # Process each document object here\n",
    "  doc = loader.load() \n",
    "  docs.append(doc)\n",
    "  pass\n",
    "\n",
    "# docs = loader.load()  # This will return a list of Document objects\n",
    "\n",
    "\n",
    "# loader = GenericLoader(YoutubeAudioLoader(urls, save_dir))\n",
    "\n",
    "# Load the audio files and transcribe them to text\n",
    "# docs = loader.load()\n",
    "\n",
    "# Convert downloaded audio files to MP3\n",
    "for doc in docs:\n",
    "    input_file = doc.metadata['audio_path']\n",
    "    output_file = os.path.splitext(input_file)[0] + \".mp3\"\n",
    "    convert_to_mp3(input_file, output_file)\n",
    "\n",
    "print(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "\n",
    "path_yt_audios_dump = '../yt_audios/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd8c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_youtube = ['https://www.youtube.com/watch?v=YSsUKckE5V0','https://www.youtube.com/watch?v=lS6fZA6zGAo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_audio = YoutubeAudioLoader([url[:1]], path_yt_audios_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0fbf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = []\n",
    "for url in urls_youtube:\n",
    "  print([url])\n",
    "  # clearing temp directory ensure url will be the only file\n",
    "  # in the directory, and metadata source is the url\n",
    "  # clear_temp_directory(path_temp_directory)\n",
    "  loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], path_yt_audios_dump),\n",
    "    # OpenAIWhisperParser()\n",
    "  )\n",
    "\n",
    "  audio = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for url in urls_youtube:\n",
    "  print([url])\n",
    "  # clearing temp directory ensure url will be the only file\n",
    "  # in the directory, and metadata source is the url\n",
    "  clear_temp_directory(path_temp_directory)\n",
    "  loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], path_temp_directory),\n",
    "    OpenAIWhisperParser()\n",
    "  )\n",
    "  doc = loader.load()\n",
    "  doc[0].metadata['source'] = url\n",
    "  docs.extend(doc)  # copy list content of _doc to list _docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474efcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71553015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d7c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from py3810.myUtils import pickle_dump, pickle_load\n",
    "\n",
    "# Set the path to the directory containing the Excel file\n",
    "path_lumen_dump = \"../langchain/docs/lumen/\"\n",
    "path_lumen_docs = path_lumen_dump + \"docs/\"\n",
    "path_save_audios = path_lumen_docs + \"youtube_audio/\"\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv('.env\\my_api_key.env')) # read local .env file\n",
    "\n",
    "SECRET_KEY1 = os.environ.get(\"SECRET_KEY\")\n",
    "DATABASE_PASSWORD2 = os.environ.get(\"DATABASE_PASSWORD\")\n",
    "print(f\"SECRET_KEY = {SECRET_KEY1}\")\n",
    "print(f\"DATABASE_PASSWORD = {DATABASE_PASSWORD2}\")\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2231f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_youtube = pickle_load(path_pickle_dump=path_lumen_dump, filename_pickle='lumen_urls_youtube')\n",
    "print(f'len(urls_youtube): {len(urls_youtube)}')\n",
    "urls_youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf9d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "dict_yt = {}\n",
    "\n",
    "for url in urls_youtube:\n",
    "  yt = YouTube(url)\n",
    "  title = yt.title\n",
    "  dict_yt[url]= title \n",
    "\n",
    "dict_yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68661363",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_yt['https://www.youtube.com/watch?v=yVF2oczrJ8w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a temporary directory\n",
    "path_temp_directory = path_save_audios+'_trash/'\n",
    "\n",
    "# Check if directory exists (optional)\n",
    "if not os.path.exists(path_temp_directory):\n",
    "  # Create the directory\n",
    "  os.makedirs(path_temp_directory)\n",
    "  print(f\"Directory '{path_temp_directory}' created successfully!\")\n",
    "else:\n",
    "  print(f\"Directory '{path_temp_directory}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def clear_temp_directory(path_temp_directory):\n",
    "  \"\"\"\n",
    "  Removes all files from a specified temporary directory.\n",
    "\n",
    "  Args:\n",
    "      path_temp_directory (str): The path to the temporary directory.\n",
    "\n",
    "  Raises:\n",
    "      OSError: If an error occurs while removing a file.\n",
    "  \"\"\"\n",
    "\n",
    "  for filename in os.listdir(path_temp_directory):\n",
    "    file_path = os.path.join(path_temp_directory, filename)\n",
    "    try:\n",
    "      os.remove(file_path)\n",
    "    except OSError as e:\n",
    "      print(f\"Error removing file {file_path}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "# path_temp_directory = \"/path/to/your/temp/directory\"\n",
    "# clear_temp_directory(path_temp_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd724587",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for url in urls_youtube:\n",
    "  print([url])\n",
    "  # clearing temp directory ensure url will be the only file\n",
    "  # in the directory, and metadata source is the url\n",
    "  clear_temp_directory(path_temp_directory)\n",
    "  loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url], path_temp_directory),\n",
    "    OpenAIWhisperParser()\n",
    "  )\n",
    "  doc = loader.load()\n",
    "  doc[0].metadata['source'] = url\n",
    "  docs.extend(doc)  # copy list content of _doc to list _docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbe9200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle_dump(file_to_pickle=docs, filename_pickle='lumen_docs_youtube', path_pickle_dump=path_lumen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ceded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b9f8fb9",
   "metadata": {},
   "source": [
    "# TODO add metadata for title, description, keyword???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84236d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pickle_load(filename_pickle='lumen_docs_youtube', path_pickle_dump=path_lumen_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "  metadata = doc.metadata\n",
    "  url_yt = metadata['source']\n",
    "  print(f'{url_yt} {metadata}')\n",
    "  # url_yt = doc.metadata['source']\n",
    "  # description_yt = doc.metadata['description']\n",
    "  # print(f'{i}: {url_yt} {description_yt}')\n",
    "  # description = dict_yt[url_yt]\n",
    "  # print(f'{i}: {url_yt}: {description}')\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
