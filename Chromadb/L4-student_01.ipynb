{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f057401b-a4ee-462a-9ba9-3e342e06eb1a",
   "metadata": {},
   "source": [
    "## Lab 4 - Cross-encoder re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5536f0-651c-40e7-aa15-27ee0cda80b7",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# from helper_utils import load_chroma, word_wrap, project_embeddings\n",
    "# from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748b16d-d4a7-49c3-a48a-57dcfc42acd6",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "# chroma_collection = load_chroma(filename='microsoft_annual_report_2022.pdf', collection_name='microsoft_annual_report_2022', embedding_function=embedding_function)\n",
    "# chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad914ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from helper_utils_02 import load_pdf_chroma, word_wrap, project_embeddings,flatten\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from py3810.myUtils import pickle_dump, pickle_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4adfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory to store the database files\n",
    "path_chromadb_dump = '../Chromadb/'\n",
    "persist_dir = '../Chromadb/collections/'\n",
    "is_persistent = True\n",
    "\n",
    "filename_pdf = 'microsoft_annual_report_2022.pdf'\n",
    "collection_name = 'microsoft_annual_report_2022'\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()  # creates 384 dimension vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204f4ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded embeddings, umpa_transform, projected_dataset_embeddings\n"
     ]
    }
   ],
   "source": [
    "if is_persistent:\n",
    "  try:\n",
    "    client = chromadb.PersistentClient(path=persist_dir)\n",
    "    chroma_collection = client.get_collection(name=collection_name, embedding_function=embedding_function)\n",
    "    embeddings = pickle_load(filename_pickle='_embeddings', path_pickle_dump=path_chromadb_dump)\n",
    "    umap_transform = pickle_load(filename_pickle='_umap_transform', path_pickle_dump=path_chromadb_dump)\n",
    "    projected_dataset_embeddings = pickle_load(filename_pickle='_projected_dataset_embeddings', path_pickle_dump=path_chromadb_dump)\n",
    "    print(f'loaded embeddings, umpa_transform, projected_dataset_embeddings')\n",
    "  except FileNotFoundError:\n",
    "    chroma_collection = \\\n",
    "      load_pdf_chroma(\n",
    "        filename_pdf=filename_pdf,\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embedding_function,\n",
    "        persist_directory=persist_dir,\n",
    "        is_persistent=is_persistent,\n",
    "      )\n",
    "    print(f'Created chroma_collection {collection_name}')\n",
    "    print(f'chroma_collection.count(): {chroma_collection.count()}')\n",
    "    embeddings = chroma_collection.get(include=['embeddings'])['embeddings']\n",
    "    umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(embeddings)\n",
    "    projected_dataset_embeddings = project_embeddings(embeddings, umap_transform)\n",
    "    print(f'created embeddings, umpa_transform, projected_dataset_embeddings')\n",
    "    pickle_dump(file_to_pickle=embeddings, filename_pickle='_embeddings', path_pickle_dump=path_chromadb_dump)\n",
    "    pickle_dump(file_to_pickle=umap_transform, filename_pickle='_umap_transform', path_pickle_dump=path_chromadb_dump)\n",
    "    pickle_dump(file_to_pickle=projected_dataset_embeddings, filename_pickle='_projected_dataset_embeddings', path_pickle_dump=path_chromadb_dump)    \n",
    "    print(f'saved embeddings, umpa_transform, projected_dataset_embeddings')\n",
    "else:\n",
    "  if os.path.exists(persist_dir):\n",
    "    client = chromadb.PersistentClient(path=persist_dir)\n",
    "    chroma_collection = client.get_collection(name=collection_name, embedding_function=embedding_function)\n",
    "    print(f'Loaded chroma_collection {collection_name}')\n",
    "    embeddings = pickle_load(filename_pickle='_embeddings', path_pickle_dump=path_chromadb_dump)\n",
    "    umap_transform = pickle_load(filename_pickle='_umap_transform', path_pickle_dump=path_chromadb_dump)\n",
    "    projected_dataset_embeddings = pickle_load(filename_pickle='_projected_dataset_embeddings', path_pickle_dump=path_chromadb_dump)\n",
    "    print(f'loaded embeddings, umpa_transform, projected_dataset_embeddings')\n",
    "    print(f'chroma_collection.count(): {chroma_collection.count()}')\n",
    "  else:\n",
    "    chroma_collection = \\\n",
    "      load_pdf_chroma(\n",
    "        filename_pdf=filename_pdf,\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embedding_function,\n",
    "        persist_directory=persist_dir,\n",
    "        is_persistent=True,  # Set True to save collection, can always delete directory\n",
    "      )\n",
    "    print(f'Created chroma_collection {collection_name}')\n",
    "    print(f'chroma_collection.count(): {chroma_collection.count()}')\n",
    "    embeddings = chroma_collection.get(include=['embeddings'])['embeddings']\n",
    "    umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(embeddings)\n",
    "    projected_dataset_embeddings = project_embeddings(embeddings, umap_transform)\n",
    "    print(f'created embeddings, umpa_transform, projected_dataset_embeddings')\n",
    "    pickle_dump(file_to_pickle=embeddings, filename_pickle='_embeddings', path_pickle_dump=path_chromadb_dump)\n",
    "    pickle_dump(file_to_pickle=umap_transform, filename_pickle='_umap_transform', path_pickle_dump=path_chromadb_dump)\n",
    "    pickle_dump(file_to_pickle=projected_dataset_embeddings, filename_pickle='_projected_dataset_embeddings', path_pickle_dump=path_chromadb_dump)    \n",
    "    print(f'saved embeddings, umpa_transform, projected_dataset_embeddings')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68486bf8-37dd-4257-a23b-9ef50c47bcc5",
   "metadata": {},
   "source": [
    "# Re-ranking the long tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888a86f8-2fe2-4682-bdaf-c15129ed1a32",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assessment of key technology trends, we maintain our long - term\n",
      "commitment to research and development across a wide spectrum of\n",
      "technologies, tools, and platforms spanning digital work and life\n",
      "experiences, cloud computing, ai, devices, and operating systems. while\n",
      "our main product research and development facilities are located in\n",
      "redmond, washington, we also operate research and development\n",
      "facilities in other parts of the u. s. and around the world. this\n",
      "global approach helps us remain competitive in local markets and\n",
      "enables us to continue to attract top talent from across the world. we\n",
      "plan to continue to make significant investments in a broad range of\n",
      "product research and development activities, and as appropriate we will\n",
      "coordinate our research and development across operating segments and\n",
      "leverage the results across the company. in addition to our main\n",
      "research and development operations, we also operate microsoft\n",
      "research. microsoft research is\n",
      "\n",
      "and business methods, we believe, based upon past experience and\n",
      "industry practice, such licenses generally can be obtained on\n",
      "commercially reasonable terms. we believe our continuing research and\n",
      "product development are not materially dependent on any single license\n",
      "or other agreement with a third party relating to the development of\n",
      "our products. investing in the future our success is based on our\n",
      "ability to create new and compelling products, services, and\n",
      "experiences for our users, to initiate and embrace disruptive\n",
      "technology trends, to enter new geographic and product markets, and to\n",
      "drive broad adoption of our products and services. we invest in a range\n",
      "of emerging technology trends and breakthroughs that we believe offer\n",
      "significant opportunities to deliver value to our customers and growth\n",
      "for the company. based on our assessment of key technology trends, we\n",
      "maintain our long - term commitment to research and development across\n",
      "a wide\n",
      "\n",
      "across the company. in addition to our main research and development\n",
      "operations, we also operate microsoft research. microsoft research is\n",
      "one of the world ’ s largest corporate research organizations and works\n",
      "in close collaboration with top universities around the world to\n",
      "advance the state - of - the - art in computer science and a broad\n",
      "range of other disciplines, providing us a unique perspective on future\n",
      "trends and contributing to our innovation.\n",
      "\n",
      "platform to turn data from its offshore turbines into insights for\n",
      "predictive maintenance. amid this dynamic environment, we delivered\n",
      "record results in fiscal year 2022 : we reported $ 198 billion in\n",
      "revenue and $ 83 billion in operating income. and the microsoft cloud\n",
      "surpassed $ 100 billion in annualized revenue for the first time. our\n",
      "responsibility as a corporation, our purpose and actions must be\n",
      "aligned with addressing the world ’ s problems, not creating new ones.\n",
      "at our very core, we need to deliver innovation that helps drive broad\n",
      "economic growth. we, as a company, will do well when the world around\n",
      "us does well. that ’ s what i believe will lead to widespread human\n",
      "progress and ultimately improve the lives of everyone. there is no more\n",
      "powerful input than digital technology to drive the world ’ s economic\n",
      "output. this is the core thesis for our being as a\n",
      "\n",
      "more powerful input than digital technology to drive the world ’ s\n",
      "economic output. this is the core thesis for our being as a company,\n",
      "but it ’ s not enough. as we drive global economic growth, we must also\n",
      "commit to creating a more inclusive, equitable, sustainable, and\n",
      "trusted future. support inclusive economic growth we must ensure the\n",
      "growth we drive reaches every person, organization, community, and\n",
      "country. this starts with increasing access to digital skills. this\n",
      "year alone, more than 23 million people accessed digital skills\n",
      "training as part of our global skills initiative.\n",
      "\n",
      "enabling increased funds into local communities. additionally, we\n",
      "enriched our supplier pipeline, reaching more than 90 percent of our\n",
      "goal to spend $ 500 million with double the number of black and african\n",
      "american - owned suppliers. we also increased the number of identified\n",
      "partners in the black partner growth initiative and continue to invest\n",
      "in the partner community through the black channel partner alliance by\n",
      "supporting events focused on business growth, accelerators, and\n",
      "mentorship. progress does not undo the egregious injustices of the past\n",
      "or diminish those who continue to live with inequity. we are committed\n",
      "to leveraging our resources to help accelerate diversity and inclusion\n",
      "across our ecosystem and to hold ourselves accountable to accelerate\n",
      "change – for microsoft, and beyond. investing in digital skills the\n",
      "covid - 19 pandemic led to record unemployment, disrupting livelihoods\n",
      "of people around the world. after helping\n",
      "\n",
      "• gross margin increased $ 3. 1 billion or 10 % driven by growth in\n",
      "windows and search and news advertising. gross margin percentage was\n",
      "relatively unchanged. • operating expenses increased $ 1. 5 billion or\n",
      "14 % driven by investments in gaming, search and news advertising, and\n",
      "windows marketing. operating expenses research and development ( in\n",
      "millions, except percentages ) 2022 2021 percentage change research and\n",
      "development $ 24, 512 $ 20, 716 18 % as a percent of revenue 12 % 12 %\n",
      "0ppt research and development expenses include payroll, employee\n",
      "benefits, stock - based compensation expense, and other headcount -\n",
      "related expenses associated with product development. research and\n",
      "development expenses also include third - party development and\n",
      "programming costs, localization costs incurred to translate software\n",
      "for international markets, and the amortization of purchased software\n",
      "code and services content.\n",
      "\n",
      "and customers around the world use microsoft technology to reduce their\n",
      "own carbon footprint. fiscal year 2021 was a year of both successes and\n",
      "challenges. while we continued to make progress on several of our\n",
      "goals, with an overall reduction in our combined scope 1 and scope 2\n",
      "emissions, our scope 3 emissions increased, due in substantial part to\n",
      "significant global datacenter expansions and growth in xbox sales and\n",
      "usage as a result of the covid - 19 pandemic. despite these scope 3\n",
      "increases, we will continue to build the foundations and do the work to\n",
      "deliver on our commitments, and help our customers and partners achieve\n",
      "theirs. we have learned the impact of our work will not all be felt\n",
      "immediately, and our experience highlights how progress won ’ t always\n",
      "be linear. while fiscal year 2021 presented us with some new learnings,\n",
      "we also made some great progress. a few examples that illuminate the\n",
      "diversity of our work include :\n",
      "\n",
      "we will continue to invest in sales, marketing, product support\n",
      "infrastructure, and existing and advanced areas of technology, as well\n",
      "as continue making acquisitions that align with our business strategy.\n",
      "additions to property and equipment will continue, including new\n",
      "facilities, datacenters, and computer systems for research and\n",
      "development, sales and marketing, support, and administrative staff. we\n",
      "expect capital expenditures to increase in coming years to support\n",
      "growth in our cloud offerings. we have operating and finance leases for\n",
      "datacenters, corporate offices, research and development facilities,\n",
      "microsoft experience centers, and certain equipment. we have not\n",
      "engaged in any related party transactions or arrangements with\n",
      "unconsolidated entities or other persons that are reasonably likely to\n",
      "materially affect liquidity or the availability of capital resources.\n",
      "\n",
      "39 liquidity and capital resources we expect existing cash, cash\n",
      "equivalents, short - term investments, cash flows from operations, and\n",
      "access to capital markets to continue to be sufficient to fund our\n",
      "operating activities and cash commitments for investing and financing\n",
      "activities, such as dividends, share repurchases, debt maturities,\n",
      "material capital expenditures, and the transition tax related to the\n",
      "tcja, for at least the next 12 months and thereafter for the\n",
      "foreseeable future. cash, cash equivalents, and investments cash, cash\n",
      "equivalents, and short - term investments totaled $ 104. 8 billion and\n",
      "$ 130. 3 billion as of june 30, 2022 and 2021, respectively. equity\n",
      "investments were $ 6. 9 billion and $ 6. 0 billion as of june 30, 2022\n",
      "and 2021, respectively. our short - term investments are primarily\n",
      "intended to facilitate liquidity and capital preservation. they consist\n",
      "predominantly of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What has been the investment in research and development?\"\n",
    "results = chroma_collection.query(query_texts=query, n_results=10, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(word_wrap(document))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5665c695-22ea-4264-b1ac-5ba720b6d78b",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a13d14-4484-46f0-8e67-277337f9d138",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(scores): 10\n",
      "scores:\n",
      "1.6141684\n",
      "-0.0895655\n",
      "-2.7713428\n",
      "-10.692507\n",
      "-10.671734\n",
      "-9.126478\n",
      "-0.40982634\n",
      "-11.017633\n",
      "-1.2966429\n",
      "-8.666394\n"
     ]
    }
   ],
   "source": [
    "pairs = [[query, doc] for doc in retrieved_documents]\n",
    "scores = cross_encoder.predict(pairs)\n",
    "print(f\"len(scores): {len(scores)}\")\n",
    "print(\"scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba6c8c5-9ce4-44d0-9223-6fdd77871f87",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ordering:\n",
      "0\n",
      "1\n",
      "6\n",
      "8\n",
      "2\n",
      "9\n",
      "5\n",
      "4\n",
      "3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(\"New Ordering:\")\n",
    "# if the index for the largest number is 5, than the 1st number printed is 5\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54cc00-eebc-4294-91bf-1a2cdce51708",
   "metadata": {},
   "source": [
    "# Re-ranking with Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377a84aa-1d93-4e97-9b2d-d59c46355338",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "original_query = \"What were the most important factors that contributed to increases in revenue?\"\n",
    "generated_queries = [\n",
    "    \"What were the major drivers of revenue growth?\",\n",
    "    \"Were there any new product launches that contributed to the increase in revenue?\",\n",
    "    \"Did any changes in pricing or promotions impact the revenue growth?\",\n",
    "    \"What were the key market trends that facilitated the increase in revenue?\",\n",
    "    \"Did any acquisitions or partnerships contribute to the revenue growth?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba0ed8ca-6640-4c09-9cb3-9de5e7cf46dc",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "n_results = 10 # number retrieved query results  \n",
    "queries = [original_query] + generated_queries\n",
    "\n",
    "results = chroma_collection.query(query_texts=queries, n_results=n_results, include=['documents', 'embeddings'])\n",
    "retrieved_documents = results['documents']\n",
    "retrieved_embeddings = results['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31afe8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "853"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_documents[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02653431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_embeddings[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bde2416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 queries\n",
      "The queries retrieved 6 retrieved_documents and 6 retrieved_embeddings\n",
      "Each retrieved document has 10 text chunks retrieved from chroma collection\n",
      "Each retrieved embedding has 10 embedding vectors from chroma collection\n"
     ]
    }
   ],
   "source": [
    "retrieved_documents = results['documents']\n",
    "retrieved_embeddings = results['embeddings']\n",
    "\n",
    "print(f'There are {len(queries)} queries')\n",
    "print(f'The queries retrieved {len(retrieved_documents)} retrieved_documents and {len(retrieved_documents)} retrieved_embeddings')\n",
    "print(f'Each retrieved document has {len(retrieved_documents[0])} text chunks retrieved from chroma collection')\n",
    "print(f'Each retrieved embedding has {len(retrieved_embeddings[0])} embedding vectors from chroma collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate the retrieved documents\n",
    "document_count = 0\n",
    "unique_documents = set()\n",
    "for documents in retrieved_documents:\n",
    "    for document in documents:\n",
    "        document_count += 1\n",
    "        unique_documents.add(document)\n",
    "\n",
    "unique_documents = list(unique_documents)\n",
    "print(f'retrieved {document_count} documents, {len(unique_documents)} are unique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f2758-0f5a-49e5-b1fa-517b91324575",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for doc in unique_documents:\n",
    "    pairs.append([original_query, doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee59493-8a99-4da8-b94f-4747efcfc79d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "scores = cross_encoder.predict(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eda9bc-ae76-4db6-9e0c-ae099d852d78",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "print(f\"len(scores): {len(scores)}\")\n",
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1183e75-4c65-422e-bc47-48010d8b29c9",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "print(\"New Ordering:\")\n",
    "# if the index for the largest number is 5, than the 1st number printed is 5\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd85cc-8898-41ed-a0aa-bd8a33fc565a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#TODO map the first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "top_n_scores = np.argsort(scores)[::-1][:n]\n",
    "top_n_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f159d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F'Top {n} pair score for query: {pairs[0][0]}:')\n",
    "for i, item in enumerate(top_n_scores):\n",
    "  print(f'{i} score: {cross_encoder.predict(pairs[item])}')\n",
    "  print(f'retrived doc: {pairs[item][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ca7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, q in enumerate(queries):\n",
    "  print(f'{i}: {len(retrieved_documents[i])} {retrieved_documents[i]}')\n",
    "  print(f'{i}: {len(retrieved_embeddings[i])} {retrieved_embeddings[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71637bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in retrieved_documents:\n",
    "    print(word_wrap(doc))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_embeddings = results['embeddings'][0]\n",
    "original_query_embedding = embedding_function([original_query])\n",
    "augmented_query_embedding = embedding_function([joint_query])\n",
    "\n",
    "projected_original_query_embedding = project_embeddings(original_query_embedding, umap_transform)\n",
    "projected_augmented_query_embedding = project_embeddings(augmented_query_embedding, umap_transform)\n",
    "projected_retrieved_embeddings = project_embeddings(retrieved_embeddings, umap_transform)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
