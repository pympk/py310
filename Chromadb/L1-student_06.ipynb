{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec889d86-0d16-477f-8b7f-be03d73ad957",
   "metadata": {},
   "source": [
    "# Lab 1 - Overview of embeddings-based retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ee2f53-d88b-4f00-94a2-75a66d4149e9",
   "metadata": {},
   "source": [
    "Welcome! Here's a few notes about the Chroma course notebooks.\n",
    " - A number of warnings pop up when running the notebooks. These are normal and can be ignored.\n",
    " - Some operations such as calling an LLM or an opeation using generated data return unpredictable results and so your notebook outputs may differ from the video.\n",
    "  \n",
    "Enjoy the course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacaa034",
   "metadata": {},
   "source": [
    "https://learn.deeplearning.ai/courses/advanced-retrieval-for-ai/lesson/2/overview-of-embeddings-based-retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2913a774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ping\\Files_win10\\python\\py310\\.venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c58cb4e14446ccad4921c77010de44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/nvidia/NV-Embed-v2\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"nvidia/NV-Embed-v2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74083979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ping\\Files_win10\\python\\py310\\.venv\\lib\\site-packages\\torch\\backends\\cuda\\__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87.97085571289062, 0.47974157333374023], [1.026376485824585, 86.3504409790039]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Each query needs to be accompanied by an corresponding instruction describing the task.\n",
    "task_name_to_instruct = {\"example\": \"Given a question, retrieve passages that answer the question\",}\n",
    "\n",
    "query_prefix = \"Instruct: \"+task_name_to_instruct[\"example\"]+\"\\nQuery: \"\n",
    "queries = [\n",
    "    'are judo throws allowed in wrestling?', \n",
    "    'how to become a radiology technician in michigan?'\n",
    "    ]\n",
    "\n",
    "# No instruction needed for retrieval passages\n",
    "passages = [\n",
    "    \"Since you're reading this, you are probably someone from a judo background or someone who is just wondering how judo techniques can be applied under wrestling rules. So without further ado, let's get to the question. Are Judo throws allowed in wrestling? Yes, judo throws are allowed in freestyle and folkstyle wrestling. You only need to be careful to follow the slam rules when executing judo throws. In wrestling, a slam is lifting and returning an opponent to the mat with unnecessary force.\",\n",
    "    \"Below are the basic steps to becoming a radiologic technologist in Michigan:Earn a high school diploma. As with most careers in health care, a high school education is the first step to finding entry-level employment. Taking classes in math and science, such as anatomy, biology, chemistry, physiology, and physics, can help prepare students for their college studies and future careers.Earn an associate degree. Entry-level radiologic positions typically require at least an Associate of Applied Science. Before enrolling in one of these degree programs, students should make sure it has been properly accredited by the Joint Review Committee on Education in Radiologic Technology (JRCERT).Get licensed or certified in the state of Michigan.\"\n",
    "]\n",
    "\n",
    "# load model with tokenizer\n",
    "# model = SentenceTransformer('nvidia/NV-Embed-v2', trust_remote_code=True)\n",
    "model.max_seq_length = 32768\n",
    "model.tokenizer.padding_side=\"right\"\n",
    "\n",
    "def add_eos(input_examples):\n",
    "  input_examples = [input_example + model.tokenizer.eos_token for input_example in input_examples]\n",
    "  return input_examples\n",
    "\n",
    "# get the embeddings\n",
    "batch_size = 2\n",
    "query_embeddings = model.encode(add_eos(queries), batch_size=batch_size, prompt=query_prefix, normalize_embeddings=True)\n",
    "passage_embeddings = model.encode(add_eos(passages), batch_size=batch_size, normalize_embeddings=True)\n",
    "\n",
    "scores = (query_embeddings @ passage_embeddings.T) * 100\n",
    "print(scores.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ba733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9100590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce03e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import chromadb\n",
    "\n",
    "from openai import OpenAI\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "from chromadb.config import Settings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pypdf import PdfReader\n",
    "from helper_utils_02 import word_wrap\n",
    "\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9872ad11",
   "metadata": {},
   "source": [
    "#### Embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a42c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model for SentenceTransformerEmbeddingFunction is \"all-MiniLM-L6-v2\"\n",
    "embedding_function = SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e834a",
   "metadata": {},
   "source": [
    "#### SentenceTransformersTokenTextSplitter hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8bce69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentenceTransformers embedding model's context windows is 256 max.\n",
    "# It will truncate the rest, after the exceeding the max. context window. \n",
    "tokens_per_chunk = 256\n",
    "tokens_chunk_overlap = int(tokens_per_chunk * 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a299c",
   "metadata": {},
   "source": [
    "#### Persistance directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a5536f0-651c-40e7-aa15-27ee0cda80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store embedding database\n",
    "is_persistent = True\n",
    "\n",
    "# Specify the directory to store the database files\n",
    "persist_dir = './persist_dir/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4828075",
   "metadata": {},
   "source": [
    "#### Load pdf to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3748b16d-d4a7-49c3-a48a-57dcfc42acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"microsoft_annual_report_2022.pdf\")\n",
    "\n",
    "# Extracting text from pages and strip leading and trailing space characters\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9138aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pdf_pages = len(pdf_texts)\n",
    "\n",
    "print(f'type(reader): {type(reader)}')\n",
    "print(f'type(pdf_texts): {type(pdf_texts)}')\n",
    "print(f'number of pdf pages: {total_pdf_pages}')\n",
    "print(f'\\npdf page 1: {pdf_texts[0][:200]} .... {pdf_texts[0][-200:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd608a5-b6c9-4ae9-a871-a3e470a4d12a",
   "metadata": {},
   "source": [
    "#### You can view the pdf in your browser [here](./microsoft_annual_report_2022.pdf) if you would like. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8aaddd",
   "metadata": {},
   "source": [
    "#### https://dev.to/eteimz/understanding-langchains-recursivecharactertextsplitter-2846"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fdf507",
   "metadata": {},
   "source": [
    "#### Split pdf text, in the order of the separators , to satisfy chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff786f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates an instance of RecursiveCharacterTextSplitter\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    # list of delimiters used to split the text,\n",
    "    # it split text in the order of the separators, to satisfy chunk_size\n",
    "    # \"\": An empty string (effectively splitting on every character) \n",
    "    # separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"],  # remove \"\" separator, don't split on character    \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "#  concatenate pdf pages using \"\\n\\n\" (two newlines) as a delimiter.\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_n_chunk = 300\n",
    "total_character_split_texts_chunks = len(character_split_texts)\n",
    "\n",
    "print(f'The {total_pdf_pages} pdf pages are splitted into {total_character_split_texts_chunks} chunks\\n')\n",
    "print(f'Text in chunk[{_n_chunk}]: {character_split_texts[_n_chunk]}')\n",
    "print(f\"\\nNumber of characters in chunk[{_n_chunk}]: {len(character_split_texts[_n_chunk])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf261faa",
   "metadata": {},
   "source": [
    "#### Splitting text into tokens is the first step of any RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5665c695-22ea-4264-b1ac-5ba720b6d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=tokens_chunk_overlap, tokens_per_chunk=tokens_per_chunk)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "total_token_split_texts_chunks = len(token_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The {total_character_split_texts_chunks} character_split_texts chunks are split into {total_token_split_texts_chunks} token_split_texts chunks')\n",
    "print(f'token_split_texts[{_n_chunk}]: {token_split_texts[_n_chunk]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb33f5e",
   "metadata": {},
   "source": [
    "#### Example of embedding text. An embedding vector of a single word or a chunk of text, both vectors have the same dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e51a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _texts = [['hello'], [token_split_texts[10]]]\n",
    "_texts = [['hello'], [' '], ['world'], ['hello world']]\n",
    "for _text in _texts:\n",
    "  # emb_text = [token_split_texts[10]]\n",
    "  emb_text = _text\n",
    "  emb_vector = embedding_function(emb_text)[0]  # list has only 1 vector \n",
    "  emb_vector_dim = len(emb_vector)\n",
    "\n",
    "  print(f'text to be embedded: {_text}')\n",
    "  print(f'embedding vector: {emb_vector}')\n",
    "  print(f'embedding vector dimension: {emb_vector_dim}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_texts = [['hello world']]\n",
    "# _texts = [['hello'], [' '], ['world']]\n",
    "summed_emb_vector2 = np.zeros(len(embedding_function(_texts[0])[0]))\n",
    "\n",
    "for _text in _texts:\n",
    "    emb_text = _text\n",
    "    emb_vector = embedding_function(emb_text)[0]\n",
    "    summed_emb_vector2 += emb_vector\n",
    "\n",
    "print(summed_emb_vector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3941e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# _texts = [['hello'], [' '], ['world'], ['hello world']]\n",
    "_texts = [['hello'], [' '], ['world']]\n",
    "summed_emb_vector = np.zeros(len(embedding_function(_texts[0])[0]))\n",
    "\n",
    "for _text in _texts:\n",
    "    emb_text = _text\n",
    "    emb_vector = embedding_function(emb_text)[0]\n",
    "    summed_emb_vector += emb_vector\n",
    "\n",
    "print(summed_emb_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ffa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_hello = np.array(embedding_function('hello'))  # list has only 1 vector \n",
    "vect_space = np.array(embedding_function(' '))  # list has only 1 vector \n",
    "vect_world = np.array(embedding_function('world'))  # list has only 1 vector \n",
    "vect_hello_world = np.array(embedding_function('hello world'))  # list has only 1 vector \n",
    "\n",
    "\n",
    "print(f'vect_hello:       {vect_hello[:5]} ...')\n",
    "print(f'vect_space:       {vect_space[:5]} ...')\n",
    "print(f'vect_world:       {vect_world[:5]} ...')\n",
    "print(f'vect_hello_world: {vect_hello_world[:5]} ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4388e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_hello = np.array(embedding_function(hello)[0])  # list has only 1 vector \n",
    "vect_space = np.array(embedding_function(space)[0])  # list has only 1 vector \n",
    "vect_world = np.array(embedding_function(world)[0])  # list has only 1 vector \n",
    "vect_hello_world = np.array(embedding_function('hello world'))  # list has only 1 vector \n",
    "\n",
    "print(f'vect_hello:       {vect_hello[:5]} ...')\n",
    "print(f'vect_space:       {vect_space[:5]} ...')\n",
    "print(f'vect_world:       {vect_world[:5]} ...')\n",
    "print(f'vect_hello_world: {vect_hello_world[:5]} ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dbea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vect_sum = np.add(vect_hello, vect_space, vect_world)\n",
    "vect_net = np.subtract(vect_sum, vect_hello_world)\n",
    "# print(vect_sum)\n",
    "vect_net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa481059",
   "metadata": {},
   "source": [
    "#### Create a collection and add documents to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16af73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chroma client\n",
    "client = chromadb.Client(Settings(is_persistent=is_persistent, persist_directory=persist_dir))  \n",
    "\n",
    "# Create or retrieve a collection\n",
    "collection_name = \"microsoft_annual_report_2022\"\n",
    "collection = client.get_or_create_collection(name=collection_name, embedding_function=embedding_function)\n",
    "\n",
    "# Add documents to the collection, and will overwrite existing document with the same ids\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "collection.add(ids=ids, documents=token_split_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d572d",
   "metadata": {},
   "source": [
    "#### Retrieve a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a3bf195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or retrieve a collection\n",
    "collection_name = \"microsoft_annual_report_2022\"\n",
    "collection = client.get_or_create_collection(name=collection_name, embedding_function=embedding_function)\n",
    "\n",
    "# Retrieve the whole embedding database\n",
    "results = collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a20f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_keys = []\n",
    "print(f\"Results is a dictionary. Here are the keys and values (values is a list):\")\n",
    "for k, v in results.items():\n",
    "  results_keys.append(k)\n",
    "  print(f'key: {k}, value: {v}')\n",
    "\n",
    "print(f'\\nresults keys:\\n{results_keys}')\n",
    "\n",
    "# Get the first document\n",
    "print(f'\\nText in the first document:')\n",
    "print(f'results[\"documents\"][0]: {results[\"documents\"][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a7e90f",
   "metadata": {},
   "source": [
    "#### Get a subset of a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca06c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_retrieve = [\"0\", \"1\"]\n",
    "subset = collection.get(\n",
    "  ids=ids_to_retrieve,\n",
    ")\n",
    "print(f'subset of collection by ids:')\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9af82356",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "          \"What was the total revenue from the income statement?\", \\\n",
    "           \"What was the operating margin?\", \\\n",
    "           \"What is the Operating income from the Income Statements\", \\\n",
    "           \"What is the cost of good sold from the Income Statement\", \\\n",
    "           \"What is the beginning inventory from the Balance Sheet\", \\\n",
    "           \"What is the ending inventory from the Balance Sheet\", \\\n",
    "           \"What is the Beginning Accounts Receivable from current asset on the balance sheet\", \\\n",
    "           \"What is the Ending Accounts Receivable from current asset on the balance sheet\", \\\n",
    "            ]\n",
    "\n",
    "results = collection.query(query_texts=queries, n_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, query in enumerate(queries):\n",
    "  retrieved_documents = results['documents'][i]\n",
    "  retrieved_ids = results['ids'][i]  \n",
    "  for j, document in enumerate(retrieved_documents):\n",
    "    print(f\"query: {queries[i]}\")\n",
    "    # print(word_wrap(document, n_chars=90))\n",
    "    print(f\"document: {j}, ids={retrieved_ids[j]}: {word_wrap(document, n_chars=90)}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377a84aa-1d93-4e97-9b2d-d59c46355338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_ = load_dotenv(find_dotenv('.env\\my_api_key.env')) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rag_35(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "def rag_4o(query, retrieved_documents, model=\"gpt-4o-mini\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba0ed8ca-6640-4c09-9cb3-9de5e7cf46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rag_35(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "def rag_4o(query, retrieved_documents, model=\"gpt-4o-mini\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "666656b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_35(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027fb5e",
   "metadata": {},
   "source": [
    "Where to Find Key Metrics in Financial Statements\n",
    "Cost of Goods Sold (COGS):\n",
    "\n",
    "Income Statement: COGS is typically found on the income statement, usually listed below revenue. It represents the direct costs associated with producing or purchasing goods sold.   \n",
    "Average Inventory:\n",
    "\n",
    "Balance Sheet: Inventory is listed as a current asset on the balance sheet. To calculate average inventory, you'll need the beginning and ending inventory balances for the period.\n",
    "Average Inventory = (Beginning Inventory + Ending Inventory) / 2   \n",
    "  \n",
    "Net Credit Sales:\n",
    "\n",
    "Income Statement: This figure can be found on the income statement. It represents the total sales made on credit during the period.   \n",
    "Average Accounts Receivable:\n",
    "\n",
    "Balance Sheet: Accounts receivable is listed as a current asset. Similar to average inventory, calculate average accounts receivable by using the beginning and ending balances.\n",
    "Average Accounts Receivable = (Beginning Accounts Receivable + Ending Accounts Receivable) / 2   \n",
    "  \n",
    "Note: The specific labels or placement of these items might vary slightly depending on the company and the accounting standards they follow. However, these general guidelines should help you locate the necessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, query in enumerate(queries):\n",
    "  retrieved_documents = results['documents'][i]\n",
    "  retrieved_ids = results['ids'][i]\n",
    "  output = rag_4o(query=query, retrieved_documents=retrieved_documents)    \n",
    "  for j, document in enumerate(retrieved_documents):\n",
    "    print(f\"query: {queries[i]}\")\n",
    "    print(f\"document: {j}, ids={retrieved_ids[j]}: {word_wrap(document, n_chars=90)}\")\n",
    "    print('\\n')\n",
    "  \n",
    "  print(f'{\"=\"*40}')\n",
    "  print(f\"query: {queries[i]}\")\n",
    "  print(f'output: {word_wrap(output, n_chars=90)}')\n",
    "  print(f'{\"=\"*40}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7393a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
